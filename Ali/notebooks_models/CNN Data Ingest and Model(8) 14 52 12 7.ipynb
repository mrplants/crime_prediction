{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/muhammadayub/Desktop/CS230/Notebooks/re'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanURL(url):\n",
    "    p = pathlib.Path(url)\n",
    "    path = str(p.as_posix()) \n",
    "    return path \n",
    "\n",
    "\n",
    "def getDF(loc, sheetname):\n",
    "    dataframe = pd.read_excel(loc, sheetname)\n",
    "    #https://stackoverflow.com/questions/40950310/strip-trim-all-strings-of-a-dataframe\n",
    "    dataframe = dataframe.applymap(lambda x: x.strip() if type(x) is str else x)\n",
    "    return dataframe\n",
    "\n",
    "def printNulls(df):\n",
    "    null_columns = df.columns[df.isnull().any()]\n",
    "    return df[null_columns].isnull().sum() \n",
    "\n",
    "\n",
    "def writeDFToFile(dfs, path_): #dfs is an array of dataframes and their sheet names , path needs to have\n",
    "    time_ = str(datetime.datetime.now())\n",
    "    current_date_time = time_[0:time_.index(\".\")]\n",
    "    current_date_time = current_date_time.replace(\":\", \"-\")\n",
    "    task4_fileoutput = path_+current_date_time+\".xlsx\"\n",
    "\n",
    "    writer = pd.ExcelWriter(task4_fileoutput)\n",
    "    \n",
    "    for df_tuple in dfs:  \n",
    "        df = df_tuple[0]\n",
    "        sheetName = df_tuple[1]\n",
    "        df.to_excel(writer, sheetName)\n",
    "    print(\"file written to :       \" + task4_fileoutput)\n",
    "    writer.save()\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the data loader methodology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# Constants \n",
    "################\n",
    "BATCHSIZE_Y = 3000\n",
    "LAST_BATCHSIZE_Y = 3000\n",
    "TIMES_OF_DAY = 24\n",
    "#The last day since the LEntries data only goes to 6/20/2018, we should filter to that end \n",
    "LAST_DAY = 6350 # in terms of timedelta.days\n",
    "#FIRST_DAY was 1/1/2001, last day should then be 6/30/2018\n",
    "MINIBATCHES_AMT = 762 #or (200,762) (254 batches of 600) (gcf of 3000 and 152400) # keep in mind that this number is going to be scaled by 16 since 16 64by64 images are in one 256by256\n",
    "#150 or 1016              #batch size should never be more than 2900 (really 3000, but to stay on the safe side)\n",
    "iHeight = 256\n",
    "iWidth = 256\n",
    "\n",
    "\n",
    "################\n",
    "# Load all the data , for the larger data values , just run  \n",
    "################\n",
    "\n",
    "# load all the data #CHANGEME\n",
    "# datesb = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\dates_data_b.npy'))\n",
    "# dates = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\dates_data.npy'))\n",
    "# buildings = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\x__buildings_b.npy'))\n",
    "datesb = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/dates_data_b.npy'))\n",
    "dates = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/dates_data.npy'))\n",
    "buildings = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/x__buildings_b.npy'))\n",
    "\n",
    "\n",
    "\n",
    "#make sure there are no nan values in buildings \n",
    "mask = np.isnan(buildings)\n",
    "indices = np.where(mask ==True)\n",
    "z = indices[0]\n",
    "y = indices[1]\n",
    "x = indices[2]\n",
    "buildings[z,y,x] = -1\n",
    "\n",
    "# businesses = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\x__businesses_b.npy'))\n",
    "# socio = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\x__socio_b.npy'))\n",
    "# lentries = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\x__Lentries_c.npy'), mmap_mode  = 'r')\n",
    "# waterway = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\waterway.npy'))\n",
    "businesses = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/x__businesses_b.npy'))\n",
    "socio = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/x__socio_b.npy'))\n",
    "lentries = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/x__Lentries_c.npy'))#, mmap_mode  = 'r')#CHANGEME\n",
    "waterway = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/waterway.npy'))\n",
    "##KLUDGE: This is a quick fix, just set a lot of the data to 0\n",
    "# waterway[:,170:]= 1\n",
    "\n",
    "#get all the masks used\n",
    "\n",
    "################\n",
    "# Preprocess every image value to be its transpose\n",
    "################\n",
    "# buildings  buildingsT -> buildingsTStacked\n",
    "# businesses    businessesT -> businessesTStacked\n",
    "# socio   socioT -> socioTStacked\n",
    "buildingsT= transpose3dImage(buildings)\n",
    "businessesT= transpose3dImage(businesses)\n",
    "socioT = transpose3dImage(socio)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "waterway = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/waterway.npy'))\n",
    "plt.imshow(waterway)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the outputs\n",
    "outputsData =[]\n",
    "for i_ in range(1, 53): # /home/muhammadayub/Desktop/CS230/training_data/outputs/y__c2_127.npy\n",
    "    y_ = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/outputs/y__c'+str(i_)+'_127.npy'), mmap_mode  = 'r')\n",
    "    outputsData.append(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-270-c84188cdcd05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# if at all possible  #CHANGEME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutputsDataReal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputsData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputsDataReal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputsData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutputsData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if at all possible  #CHANGEME\n",
    "outputsDataReal = np.concatenate(outputsData, axis = 0)\n",
    "print(outputsDataReal.shape)\n",
    "for i_ in range(len(outputsData)):\n",
    "    outputsData[i_] =None\n",
    "    \n",
    "# if at all possible  #CHANGEME\n",
    "for i_ in range(len(outputsDataReal)):\n",
    "    outputsDataReal[i_] =outputsDataReal[i_].T\n",
    "print('run once')\n",
    "# print(outputsDataReal.max())#33 is max, 0 is min\n",
    "# print(outputsDataReal.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to print the waterway mask\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plotImg(img):\n",
    "    if(type(img) ==type(None)):\n",
    "        img =outputsDataReal[10000]\n",
    "    arr = []\n",
    "    for a in img:\n",
    "        arr = [a] + arr\n",
    "    plt.pcolor( arr, cmap = 'gist_ncar' )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4833"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = np.where(outputsDataReal[1000:10000] !=0)\n",
    "# plotImg(outputsDataReal[1000])\n",
    "len(abc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the data (to align all the indices of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lentries.shape\n",
    "print(len(lentries)*24)\n",
    "print(len(lentries))\n",
    "# len of everything \n",
    "print('number of outputs ' , BATCHSIZE_Y*51+len(outputsData[-1])) # number of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data points 152400\n",
      "will shave off extra data. Everything starts from the same point in time\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculate the exact value of how many (256 by 256 by numlayer) images we should have \n",
    "indices = LAST_DAY* TIMES_OF_DAY\n",
    "indices_ = np.array([index for index in range(indices)])\n",
    "print('Actual data points', len(indices_)) # 0 - 153,335 or 153,336 values                      #152400\n",
    "print(\"will shave off extra data. Everything starts from the same point in time\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate minibatches. Shuffle the minibatches, have a function to return a minibatch of X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762\n",
      "685 38 39\n"
     ]
    }
   ],
   "source": [
    "print(MINIBATCHES_AMT)\n",
    "train_split = int(MINIBATCHES_AMT*.90)\n",
    "dev_split = int(MINIBATCHES_AMT*.05)\n",
    "test_split = MINIBATCHES_AMT - train_split - dev_split\n",
    "\n",
    "print(train_split, dev_split, test_split)\n",
    "assert(train_split + dev_split + test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of datapoints [     0      1      2 ... 152397 152398 152399]\n"
     ]
    }
   ],
   "source": [
    "print('Indices of datapoints', indices_)\n",
    "#gets the indices of the minibatches\n",
    "\n",
    "minibatches = np.split(indices_,MINIBATCHES_AMT)\n",
    "backup_minibatches = copy.deepcopy(minibatches)\n",
    "\n",
    "devMiniBatches = minibatches[train_split:train_split+dev_split]\n",
    "testMiniBatches = minibatches[train_split+dev_split:-1]# remove the last minibatch\n",
    "minibatches = minibatches[:train_split] #training set  #must be at the end\n",
    "\n",
    "# sample = np.array(minibatches[0])\n",
    "# print('sample minibatch: ' , sample )\n",
    "# #to shuffle the minibatches for random minibatches  we will do this every epoch\n",
    "# np.random.shuffle(minibatches)\n",
    "# print(devMiniBatches)\n",
    "# print(testMiniBatches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(devMiniBatches+testMiniBatches+minibatches)\n",
    "inputImage = None\n",
    "output_image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# datesb -- no need \n",
    "# dates -- no need\n",
    "# buildings  buildingsT -> buildingsTStacked\n",
    "# businesses    businessesT -> businessesTStacked\n",
    "# socio   socioT -> socioTStacked\n",
    "# lentries \n",
    "# waterway  -- not part of data \n",
    "# outputsData \n",
    "\n",
    "\n",
    "#next steps -> add lentries, temperature, and masks \n",
    "\n",
    "# now we write a function that will return to us the correct minibatch , with all the image data generated\n",
    "def generateMinibatch(minibatchIndices):    #everything must be transposed\n",
    "    #general steps:\n",
    "    #get the x inputs\n",
    "    #    same as the file of text \n",
    "    \n",
    "    #step 1. dates (make 12 layers of month, day, year , timeOfDay)  # dateLayers don't need to be transposed -> just 1 value\n",
    "    dateLayers = generateDatesLayers(minibatchIndices, datesb) # (150, 256, 256, 4)  => len(minibatchIndices) = 150\n",
    "    \n",
    "    #step 2. Buildings 10 layers \n",
    "    buildingLayers = stackManyTimes(buildingsT, len(minibatchIndices))  # buildingsT should be (256,256,10) and result should (150, 256, 256, 10)\n",
    "  \n",
    "    #step 3. \n",
    "    businessesLayers = stackManyTimes(businessesT, len(minibatchIndices))\n",
    "    \n",
    "    #step 4. L entries\n",
    "    #come back to this one   => must be transposed!!!\n",
    "    LentryLayers = None\n",
    "    \n",
    "    #step 5. socio\n",
    "    socioLayers = stackManyTimes(socioT, len(minibatchIndices))\n",
    "    \n",
    "    #step 6. temperature #should be format of\n",
    "    #pass on this for now -> will add this for later iterations\n",
    "    \n",
    "    #step 7. concat everything\n",
    "    inputImage = np.concatenate((dateLayers,buildingLayers,businessesLayers,socioLayers) , axis = -1)\n",
    "#     print(np.where((inputImage[:4]==dateLayers)==False))\n",
    "#     print(np.where((inputImage[4:14]==buildingLayers)==False))\n",
    "\n",
    "    #step 7. outputs\n",
    "    output_image = outputsDataReal[minibatchIndices]  # calculateOutput(minibatchIndices)\n",
    "    return inputImage, output_image#, waterway\n",
    "\n",
    "def generateDatesLayers(minibatchIndices, datesb):\n",
    "    base_img_mask = np.ones((256, 256), dtype=np.float32)\n",
    "    xy = np.dstack([base_img_mask]*4) # shape (256, 256, 4)\n",
    "    dateLayers = datesb[minibatchIndices] # (len(minibatchIndices) , 4)\n",
    "    dateLayersReshaped = dateLayers.reshape((len(dateLayers), 1,1,dateLayers.shape[1])) # (len(minibatchIndices),1,1 , 4)\n",
    "    xyz = xy* dateLayersReshaped \n",
    "    return xyz\n",
    "\n",
    "def transpose3dImage(img):\n",
    "    img_T = img.T #tested this actually does what we wante it to do.  \n",
    "    return img_T\n",
    "\n",
    "\n",
    "def stackManyTimes(_3dimg,times):\n",
    "    _3dimg_shape = _3dimg.shape\n",
    "    result = np.zeros(shape=(times, _3dimg_shape[0], _3dimg_shape[1],_3dimg_shape[2] ), dtype=np.float32)\n",
    "    for x in range(times):\n",
    "        result[x] = _3dimg\n",
    "    return result\n",
    "\n",
    "def calculateOutput(sample):\n",
    "    batchMin = min(sample)#67050\n",
    "    batchMax = max(sample)#67199\n",
    "    #     batchMax  = 69050\n",
    "    #print(\"batch min \" , batchMin,\" batch max \", batchMax )\n",
    "    remMin = batchMin % BATCHSIZE_Y\n",
    "    multipleMin = int(batchMin / BATCHSIZE_Y)\n",
    "\n",
    "    remMax = batchMax % BATCHSIZE_Y\n",
    "    multipleMax = int(batchMax / BATCHSIZE_Y)\n",
    "    \n",
    "    batch = None\n",
    "    if(multipleMin != multipleMax):# have to concatenate  batch size can never be more than 3000#\n",
    "        print('here')\n",
    "        batch = np.concatenate((outputsData[multipleMin],outputsData[multipleMax]), axis = 0)\n",
    "    else:\n",
    "        print('not here')\n",
    "        batch = outputsData[multipleMin]\n",
    "\n",
    "    offset = multipleMin*BATCHSIZE_Y\n",
    "    sample_ = np.array(sample)-offset\n",
    "    data_output = batch[sample_]\n",
    "    return data_output\n",
    "\n",
    "def splitWaterWay(waterwayImg):\n",
    "    imagesList = np.split(waterwayImg, 4, axis = 0)\n",
    "    images64by64 = []\n",
    "\n",
    "    for almostImage in imagesList:\n",
    "        imagesList64by64 = np.split(almostImage, 4, axis = 1) # axis is 0, 1, 2\n",
    "        for actual64by64 in imagesList64by64:\n",
    "            images64by64.append(actual64by64)\n",
    "    #     for i,_64 in enumerate(images64by64):\n",
    "    #         print(i, _64.shape)\n",
    "    return np.concatenate(images64by64, axis = 0)\n",
    "\n",
    "def split256by256StackOnAxis(inputImg):  #returns the images in (64 , 64, numberOfChannels)\n",
    "    imagesList = np.split(inputImg, 4, axis = 1)\n",
    "    images64by64 = []\n",
    "\n",
    "    for almostImage in imagesList:\n",
    "        imagesList64by64 = np.split(almostImage, 4, axis = 2) # axis is 0, 1, 2\n",
    "        for actual64by64 in imagesList64by64:\n",
    "            images64by64.append(actual64by64)\n",
    "    #     for i,_64 in enumerate(images64by64):\n",
    "    #         print(i, _64.shape)\n",
    "    return np.concatenate(images64by64, axis = 0)\n",
    "\n",
    "def getOutputYVector(y_output_image64, numCats): # y_output_image64 is of shape (3200,64,64)  , 34 categories + -1\n",
    "    result = np.zeros((len(y_output_image64), numCats), dtype=np.float32)\n",
    "    cCount = None \n",
    "    for i_, img in enumerate(y_output_image64):\n",
    "        cCount = Counter(img.flatten())\n",
    "        if(len(np.unique(img)) == 1): #if all -1's\n",
    "            result[i_][0] = 1\n",
    "        else: # get the second most common thing (since -1 are going to be the most common)\n",
    "            result[i_][int(cCount.most_common()[1][0])+1] = 1 # get the second value (index of 1) of most common array\n",
    "    return result\n",
    "\n",
    "    #get the argmax for now  -1 goes to 0, 0 goes to 1, etc. until you have 33 going to 34   -> kludge need to set this to -1\n",
    "    #result[i_][int(cCount.most_common()[0][0])+1] = 1\n",
    "\n",
    "def transformTo64(inputImage, output_image, numCats):\n",
    "    inputImage64 =  split256by256StackOnAxis(inputImage)\n",
    "    output_image64 = split256by256StackOnAxis(output_image)\n",
    "    output_image64 = getOutputYVector(output_image64, numCats) #34 categories since we use -1s, but then shave them off\n",
    "    return inputImage64, output_image64\n",
    "\n",
    "def generateWaterWayMask(waterway, threshold):# between 0 and 4096, need atmost 200 to be water \n",
    "    sizeOfOneMiniBatch = int(len(indices_)/MINIBATCHES_AMT)\n",
    "    waterwayMask = np.zeros((sizeOfOneMiniBatch, 256,256), dtype=np.float32)\n",
    "    for i_ in range(len(waterwayMask)):\n",
    "        waterwayMask[i_] = waterway\n",
    "        \n",
    "    #now that we have the ( 200, 256,256)  (sizeOfOneMiniBatch is 200 for example)\n",
    "    #we can break it up into the 64 by 64 images\n",
    "    waterwayMask64 = split256by256StackOnAxis(waterwayMask)\n",
    "    #from here, you count up each one of the 64 by 64 images and set to the threshold\n",
    "    waterwayMaskIndices = [] # include if they are one \n",
    "    for i_ in range(len(waterwayMask64)):\n",
    "        if(np.sum(waterwayMask64[i_]) <= threshold): #> would mean you have more 1's than allowed -> not tolerable \n",
    "            waterwayMaskIndices.append(i_)\n",
    "    return waterwayMaskIndices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition (based off research paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈2 lines)\n",
    "    X = tf.placeholder(shape =[None, n_H0, n_W0, n_C0], dtype = np.float32, name=\"X\")\n",
    "    Y = tf.placeholder(shape  =[None, n_y], dtype = np.float32 , name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X_1:0\", shape=(?, 64, 64, 26), dtype=float32)\n",
      "Y = Tensor(\"Y_1:0\", shape=(?, 34), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(64, 64, 26, 35)  #will have 35 , 34 real values and 1 fake value\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First CNN Trial\n",
    "\n",
    "### First filter shape: (10 , 10,3 , 3) stride = 2, valid padding\n",
    "    \n",
    "    (64 +2p - f)/s +1 => (64+0-10)/2+1 = 28\n",
    "    So, (?, 64, 64, 3) * (10 , 10 , 3,  3) = (?, 28, 28, 3 )\n",
    "    \n",
    "### Average Pooling Layer: (3 , 3 , 3) stride = 1, Padding = SAME\n",
    "    \n",
    "    (28 +2p - f)/s +1 => (28+2*1-3)/1+1 = 28\n",
    "    So, (?, 28, 28, 3) * ( 3 , 3,  3) = (?, 28, 28, 3 )\n",
    "    \n",
    "    \n",
    "### Second filter shape: (6 , 6 ,3, 2) stride = 2, valid padding\n",
    "    \n",
    "    (28 +2p - f)/s +1 => (28+0-6)/2+1 = 12\n",
    "    So, (?, 28, 28, 3) * (6 , 6 , 3, 2) = (?, 12, 12, 2)\n",
    "    \n",
    "### Max Pooling layer valid padding stride 1 (3,3)\n",
    "    \n",
    "    (12 +2p - f)/s +1 => (12+0-3)/1+1 = 10\n",
    "    So, (?, 12,12, 2) * (3, 3 , 2, 2) = (?, 10, 10, 2)\n",
    "\n",
    "    \n",
    "### Fourth filter shape: Flatten , fully connected (10*10*2) = 200\n",
    "    \n",
    "    W3 = 36 by 200\n",
    "    \n",
    "### Softmax function for evaluation    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():    \n",
    "\n",
    "    W1 = tf.get_variable(\"W1\", [10, 10, 26, 3], initializer =tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable(\"W2\", [6, 6, 3, 2], initializer =tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W3 = tf.get_variable(\"W3\", [35,200] , initializer =tf.contrib.layers.xavier_initializer(seed = 0) )\n",
    "\n",
    "    parameters = {\"W1\": W1, \"W2\": W2 , 'W3': 'W3'}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, params):\n",
    "    W1 = params['W1']\n",
    "    W2 = params['W2']    \n",
    "    W3 = params['W3']\n",
    "    \n",
    "    #convolution \n",
    "    Z1 = tf.nn.conv2d(X,W1, strides = [1,2,2,1], padding = 'VALID')\n",
    "    \n",
    "    #bias added automatically # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    \n",
    "    #average pooling -> at this point all features/weights are important to us\n",
    "    P1 = tf.nn.avg_pool(A1, ksize = [1,3,3,1], strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "    # convolution \n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides = [1,2,2,1], padding = 'VALID')\n",
    "    \n",
    "    #RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    \n",
    "    #max pooling\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,3,3,1], strides = [1,1,1,1], padding = 'VALID')\n",
    "    \n",
    "    #flatten\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "\n",
    "    #fully connected\n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, 35, activation_fn = None) #1 for yes/no\n",
    "    #going to add the softmax directly\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run or Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting  2018-12-07 11:27:17.292305\n",
      "Minibatch End:  2018-12-07 11:27:27.506599\n",
      "3.5461538   0   0\n",
      "3.5461538  at file name:  p/CS230/models_saved/model1/model_12_7__0_0.ckpt\n",
      "Minibatch End:  2018-12-07 11:27:37.662254\n",
      "0.2665895   0   1\n",
      "Minibatch End:  2018-12-07 11:27:47.855061\n",
      "2.1674415e-08   0   2\n",
      "2.1674415e-08  at file name:  p/CS230/models_saved/model1/model_12_7__0_2.ckpt\n",
      "Minibatch End:  2018-12-07 11:27:57.999561\n",
      "0.0   0   3\n",
      "Epoch End:  2018-12-07 11:27:57.999767\n"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph()\n",
    "base_filepath = \"/home/muhammadayub/Desktop/CS230/models_saved/model1\"\n",
    "\n",
    "learning_rate = .008\n",
    "costs = []\n",
    "num_epochs = 1\n",
    "\n",
    "WaterWayMask = generateWaterWayMask(waterway, 400)\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(): # https://stackoverflow.com/questions/36281129/no-variable-to-save-error-in-tensorflow\n",
    "\n",
    "    #variable declarations must be before tf.train.Saver() unless here: https://stackoverflow.com/questions/50974976/tensorflow-why-must-saver-tf-train-saver-be-declared-after-variables-are\n",
    "    #the model\n",
    "    X, Y = create_placeholders(64, 64, 26, 35)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_prop(X, parameters)\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#1e-4).minimize(cross_entropy)\n",
    "\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # # Initialize all the variables globally\n",
    "    # init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "\n",
    "        #init must be after optimizer\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        print('Starting ' , datetime.datetime.now())\n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            np.random.shuffle(minibatches) # get new minibatch results \n",
    "\n",
    "            for i_ , minibatch in enumerate(minibatches[:4]):\n",
    "\n",
    "                # Select a minibatch\n",
    "                inputImage, output_image = generateMinibatch(minibatch)\n",
    "                inputImage64, output_image64 = transformTo64(inputImage, output_image,34)\n",
    "                output_image64 = output_image64[WaterWayMask]\n",
    "                inputImage64 = inputImage64[WaterWayMask]\n",
    "\n",
    "\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , temp_cost = sess.run([optimizer,cost], feed_dict={X: inputImage64, Y: output_image64})\n",
    "                ### END CODE HERE ###\n",
    "\n",
    "                minibatch_cost += temp_cost / MINIBATCHES_AMT\n",
    "\n",
    "                print('Minibatch End: ', datetime.datetime.now())\n",
    "                print(temp_cost,' ' , epoch,' ' ,i_)\n",
    "                \n",
    "                if(i_ % 20 == 0 ):\n",
    "                    #save model\n",
    "                    filepath = base_filepath+\"/model_12_7__\"+str(epoch)+\"_\"+str(i_)+\".ckpt\"\n",
    "                    print(temp_cost, \" at file name: \", filepath[25:])\n",
    "                    save_path = saver.save(sess, filepath)\n",
    "\n",
    "            costs.append(minibatch_cost)\n",
    "            print('Epoch End: ', datetime.datetime.now())\n",
    "\n",
    "\n",
    "# if((epoch ==0) and (i_==0)):\n",
    "#     globalA = inputImage64\n",
    "#     globalB = output_image64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Accuracy of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restoring the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__0_0.ckpt\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "filepath = \"/home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__\"+str(0)+\"_\"+str(0)+\".ckpt\"\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(): \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        \n",
    "        #define the graph\n",
    "        X, Y = create_placeholders(64, 64, 26, 34)\n",
    "        parameters = initialize_parameters()\n",
    "        Z3 = forward_prop(X, parameters)\n",
    "        #optimization \n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#1e-4).minimize(cross_entropy)\n",
    "\n",
    "        #calculating the accuracy of the model \n",
    "        softmaxZ3 = tf.nn.softmax(Z3) # size will be 2200, 34\n",
    "        output_class = tf.argmax(softmaxZ3,1) # size will be 2200, 1 or just (2200,)\n",
    "        num_correct = tf.equal(output_class, tf.argmax(Y,1)) # must compare 2200\n",
    "        num_correct_to_int = tf.cast(num_correct, tf.float32)\n",
    "        accuracy = tf.reduce_mean(num_correct_to_int)\n",
    "        \n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        saver.restore(sess , filepath)\n",
    "        print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore the Graph and Calculate the Test Set Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__0_0.ckpt\n",
      "Model restored.\n",
      "Accuracy 100.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filepath = \"/home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__\"+str(0)+\"_\"+str(0)+\".ckpt\"\n",
    "accuracies= []\n",
    "minibatches_to_test_accuracy_of = copy.deepcopy(devMiniBatches)  # or testMiniBatches for test error \n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(): \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        \n",
    "        #define the graph\n",
    "        X, Y = create_placeholders(64, 64, 26, 34)\n",
    "        parameters = initialize_parameters()\n",
    "        Z3 = forward_prop(X, parameters)\n",
    "        #optimization \n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#1e-4).minimize(cross_entropy)\n",
    "\n",
    "        #calculating the accuracy of the model \n",
    "        softmaxZ3 = tf.nn.softmax(Z3) # size will be 2200, 34\n",
    "        output_class = tf.argmax(softmaxZ3,1) # size will be 2200, 1 or just (2200,)\n",
    "        num_correct = tf.equal(output_class, tf.argmax(Y,1)) # must compare 2200\n",
    "        num_correct_to_int = tf.cast(num_correct, tf.float32)\n",
    "        accuracy = tf.reduce_mean(num_correct_to_int)\n",
    "        \n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        saver.restore(sess , filepath)\n",
    "        print(\"Model restored.\")\n",
    "        \n",
    "        np.random.shuffle(minibatches_to_test_accuracy_of)\n",
    "        \n",
    "        #devMiniBatches \n",
    "        #testMiniBatches\n",
    "        for i_ , minibatch in enumerate(minibatches_to_test_accuracy_of[:3]):\n",
    "            inputImage, output_image = generateMinibatch(minibatch)\n",
    "            inputImage64, output_image64 = transformTo64(inputImage, output_image,34)\n",
    "            output_image64 = output_image64[WaterWayMask]\n",
    "            inputImage64 = inputImage64[WaterWayMask]\n",
    "            #temp_cost = sess.run([cost], feed_dict={X: inputImage64, Y: output_image64})\n",
    "            accuracy_val = sess.run([accuracy], feed_dict={X: inputImage64, Y: output_image64})\n",
    "            accuracies.append(accuracy_val)\n",
    "            #print('accuracy_val ', accuracy_val)\n",
    "\n",
    "            \n",
    "print('Accuracy', sum(np.array(accuracies).flatten())/len(accuracies)*100)\n",
    "\n",
    "#For Debugging below:\n",
    "#         zVal = sess.run([Z3], feed_dict={X: inputImage64, Y: output_image64})\n",
    "#         softMaxVal = sess.run([softmaxZ3], feed_dict={X: inputImage64, Y: output_image64})\n",
    "#         output_class_val = sess.run([output_class], feed_dict={X: inputImage64, Y: output_image64})\n",
    "#         num_correct_val = sess.run([num_correct], feed_dict={X: inputImage64, Y: output_image64})\n",
    "#         num_correct_to_int_val = sess.run([num_correct_to_int], feed_dict={X: inputImage64, Y: output_image64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 100.0\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy', sum(np.array(accuracies).flatten())/len(accuracies)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-06 18:59:36.103546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammadayub/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:40: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "/home/muhammadayub/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:41: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]),)\n",
      "(array([0]),)\n",
      "2018-12-06 18:59:43.296475\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "WaterWayMask = generateWaterWayMask(waterway, 400)\n",
    "inputImage, output_image = generateMinibatch(minibatches[10])\n",
    "# print(inputImage.dtype)\n",
    "# print(output_image.dtype)\n",
    "inputImage64, output_image64 = transformTo64(inputImage, output_image,34)\n",
    "# print(inputImage64.dtype)\n",
    "# print(output_image64.dtype)\n",
    "output_image64 = output_image64[WaterWayMask]\n",
    "inputImage64 = inputImage64[WaterWayMask]\n",
    "# print(inputImage64.dtype)\n",
    "# print(output_image64.dtype)\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 64, 64, 26)\n",
      "(1600, 34)\n",
      "float64\n",
      "float64\n",
      "1600\n"
     ]
    }
   ],
   "source": [
    "print(inputImage64.shape)\n",
    "print(output_image64.shape)\n",
    "print(inputImage64.dtype)\n",
    "print(output_image64.dtype)\n",
    "print(len(WaterWayMask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For back up testing and everything "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 64, 64)\n",
      "(3200, 34)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(output_image.shape)\n",
    "\n",
    "# output = getOutputYVector(output_image,34)\n",
    "# print(output.shape)\n",
    "# output[0]\n",
    "\n",
    "# result = np.zeros((len(output_image), 34))\n",
    "# cCount = None \n",
    "# for i_, img in enumerate(output_image):\n",
    "#     cCount = Counter(img.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Water Way Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799]\n"
     ]
    }
   ],
   "source": [
    "def generateWaterWayMask(waterway, threshold):# between 0 and 4096, need atmost 200 to be water \n",
    "    sizeOfOneMiniBatch = int(len(indices_)/MINIBATCHES_AMT)\n",
    "    waterwayMask = np.zeros((sizeOfOneMiniBatch, 256,256), dtype=np.float32)\n",
    "    for i_ in range(len(waterwayMask)):\n",
    "        waterwayMask[i_] = waterway\n",
    "        \n",
    "    #now that we have the ( 200, 256,256)  (sizeOfOneMiniBatch is 200 for example)\n",
    "    #we can break it up into the 64 by 64 images\n",
    "    waterwayMask64 = split256by256StackOnAxis(waterwayMask)\n",
    "    #from here, you count up each one of the 64 by 64 images and set to the threshold\n",
    "    waterwayMaskIndices = [] # include if they are one \n",
    "    for i_ in range(len(waterwayMask64)):\n",
    "        if(np.sum(waterwayMask64[i_]) <= threshold): #> would mean you have more 1's than allowed -> not tolerable \n",
    "            waterwayMaskIndices.append(i_)\n",
    "    return waterwayMaskIndices\n",
    "\n",
    "ww = np.ones((256,256))\n",
    "ww[:64, (256-64):] = 0\n",
    "\n",
    "abc = generateWaterWayMask(ww, 5)\n",
    "len(abc)\n",
    "print(abc)  # think it works \n",
    "\n",
    "# len(minibatches[10])\n",
    "#stack waterway image by "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for getting the output data (1 hot encoded vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split256by256StackOnAxis(inputImg):\n",
    "    imagesList = np.split(inputImg, 4, axis = 1)\n",
    "    images64by64 = []\n",
    "\n",
    "    for almostImage in imagesList:\n",
    "        imagesList64by64 = np.split(almostImage, 4, axis = 2) # axis is 0, 1, 2\n",
    "        for actual64by64 in imagesList64by64:\n",
    "            images64by64.append(actual64by64)\n",
    "    #     for i,_64 in enumerate(images64by64):\n",
    "    #         print(i, _64.shape)\n",
    "    return np.concatenate(images64by64, axis = 0)\n",
    "\n",
    "def getOutputYVector(y_output_image64, numCats): # y_output_image64 is of shape (3200,64,64)  , 34 categories + -1\n",
    "    result = np.zeros((len(y_output_image64), numCats), dtype=np.float32)\n",
    "    cCount = None \n",
    "    for i_, img in enumerate(y_output_image64):\n",
    "        cCount = Counter(img.flatten())\n",
    "        result[i_][int(cCount.most_common()[0][0])] = 1\n",
    "        #get the argmax for now  -1 goes to 0, 0 goes to 1, etc. until you have 33 going to 34\n",
    "#         result[i_][int(cCount.most_common()[0][0])+1] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1., 2.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[1., 2.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[1., 2.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[1., 2.],\n",
       "        [3., 4.]]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exploring things\n",
    "base_img_mask = np.ones((2, 2), dtype=np.float32)\n",
    "print(base_img_mask.shape)\n",
    "base_img_mask[0,0] = 1\n",
    "base_img_mask[0,1] = 2\n",
    "base_img_mask[1,0] = 3\n",
    "base_img_mask[1,1] = 4\n",
    "\n",
    "base_img_mask\n",
    "\n",
    "np.array([base_img_mask]*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Copy Generation of an image ( numLayers, 256, 256) to  (256, 256, numLayers) and then to  (sampleNum, 256, 256, numLayers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 4)\n",
      "(150, 4)\n",
      "(150, 1, 1, 4)\n",
      "-0.4995\n",
      "{-0.4995}\n"
     ]
    }
   ],
   "source": [
    "###Testing Dates \n",
    "\n",
    "base_img_mask = np.ones((256, 256), dtype=np.float32)\n",
    "xy = np.dstack([base_img_mask]*4)\n",
    "print(xy.shape)\n",
    "\n",
    "dateLayers = datesb[minibatchIndices]\n",
    "print(dateLayers.shape)\n",
    "dateLayersReshaped = dateLayers.reshape((len(dateLayers), 1,1,dateLayers.shape[1]))\n",
    "print(dateLayersReshaped.shape)\n",
    "\n",
    "\n",
    "xyz = xy* dateLayersReshaped \n",
    "xyz.shape\n",
    "\n",
    "#do some checks \n",
    "firstVal = dateLayers[45][1] #last layer, 2nd d value\n",
    "print(firstVal)\n",
    "\n",
    "print(set(xyz[45, :,:, 1].flatten()))\n",
    "#change the 45 and the 1 and see if things match! \n",
    "\n",
    "def generateDatesLayers(minibatchIndices, datesb):\n",
    "    base_img_mask = np.ones((256, 256), dtype=np.float32)\n",
    "    xy = np.dstack([base_img_mask]*4) # shape (256, 256, 4)\n",
    "    dateLayers = datesb[minibatchIndices] # (len(minibatchIndices) , 4)\n",
    "    dateLayersReshaped = dateLayers.reshape((len(dateLayers), 1,1,dateLayers.shape[1])) # (len(minibatchIndices),1,1 , 4)\n",
    "    xyz = xy* dateLayersReshaped \n",
    "    return xyz\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Null values\n",
    "mask = np.isnan(buildings)\n",
    "indices = np.where(mask ==True)\n",
    "z = indices[0]\n",
    "y = indices[1]\n",
    "x = indices[2]\n",
    "buildings[z,y,x] = -1\n",
    "\n",
    "# mask2 = np.isnan(buildingsTest)\n",
    "# indices2 = np.where(mask2 ==True)\n",
    "# print(indices2)\n",
    "# print(len(indices))\n",
    "# print((indices[0].flatten().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2]\n",
      "  [ 3  4]]\n",
      "\n",
      " [[ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]]]\n",
      "(3, 2, 2)\n",
      "[[5 7]\n",
      " [6 8]]\n",
      "(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "#For transposing images \n",
    "\n",
    "testData = np.array([[[1,2],[3,4]],\n",
    "                    [[5,6],[7,8]],\n",
    "                    [[9,10],[11,12]]])\n",
    "print(testData)\n",
    "print(testData.shape)\n",
    "\n",
    "def transpose3dImage(img):\n",
    "    img_T = img.T #tested this actually does what we wante it to do.  \n",
    "    return img_T\n",
    "\n",
    "testDataT = transpose3dImage(testData) # ( numLayers, 256, 256) to (256, 256, numLayers) \n",
    "\n",
    "print(testDataT[:,:,1])\n",
    "print(testDataT.shape)\n",
    "# dateLayers = generateDatesLayers(minibatchIndices, datesb)\n",
    "# dateLayers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 10)\n",
      "(4, 256, 256, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For  (256, 256, numLayers) and then to (sampleNum, 256, 256, numLayers) \n",
    "\n",
    "def stackManyTimes(_3dimg,times):\n",
    "    _3dimg_shape = _3dimg.shape\n",
    "    result = np.zeros(shape=(times, _3dimg_shape[0], _3dimg_shape[1],_3dimg_shape[2] ), dtype=np.float32)\n",
    "    for x in range(times):\n",
    "        result[x] = _3dimg\n",
    "    return result\n",
    "    \n",
    "buildings2 = np.array(transpose3dImage(buildings))\n",
    "print(buildings2.shape)\n",
    "\n",
    "buildings3_multiplied = stackManyTimes(buildings2, 4)\n",
    "print(buildings3_multiplied.shape)\n",
    "\n",
    "np.where((buildings3_multiplied[3]==buildings2) == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the right output from the list of 52, given that we know that batch size is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "batch min  151200  batch max  69050\n",
      "50   23\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# Getting the right output from the list of 52, we know that batch size is \n",
    "# print(minibatchIndices[])\n",
    "# dateLayers[-1][2]\n",
    "print(len(outputsData))\n",
    "\n",
    "outputsData[51].shape\n",
    "\n",
    "sample = minibatches[0]\n",
    "batchMin = min(sample)#67050\n",
    "batchMax = max(sample)#67199\n",
    "batchMax  = 69050\n",
    "print(\"batch min \" , batchMin,\" batch max \", batchMax )\n",
    "remMin = batchMin % BATCHSIZE_Y\n",
    "multipleMin = int(batchMin / BATCHSIZE_Y)\n",
    "\n",
    "remMax = batchMax % BATCHSIZE_Y\n",
    "multipleMax = int(batchMax / BATCHSIZE_Y)\n",
    "\n",
    "\n",
    "print(multipleMin,\" \",multipleMax)\n",
    "# outputsData[multipleMin-1] # 1 is really 0, 2 is really 1 , and so on. \n",
    "\n",
    "\n",
    "# batchMin\n",
    "#152300 - 152399\n",
    "# 155900 to 155917\n",
    "int(155900/BATCHSIZE_Y)\n",
    "print(remMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "batch = None\n",
    "if(multipleMin != multipleMax):# have to concatenate  batch size can never be more than 3000#\n",
    "    print('here')\n",
    "    batch = np.concatenate((outputsData[multipleMin],outputsData[multipleMax]), axis = 0)\n",
    "else:\n",
    "    print('not here')\n",
    "    batch = outputsData[multipleMin]\n",
    "    \n",
    "offset = multipleMin*BATCHSIZE_Y#+remMin\n",
    "\n",
    "print(offset)\n",
    "batch.shape\n",
    "sample_ = np.array(sample)-offset\n",
    "\n",
    "data_output = batch[sample_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not here\n"
     ]
    }
   ],
   "source": [
    "data_output.shape\n",
    "\n",
    "#very sure that we have to transpose everything -> since we transposed everything in the input layer \n",
    "for i_, img in enumerate(data_output):\n",
    "    data_output[i_] = img.T\n",
    "\n",
    "#now we make the 16, by 16 images \n",
    "\n",
    "sample = minibatches[0]\n",
    "\n",
    "def calculateOutput(sample):\n",
    "    batchMin = min(sample)#67050\n",
    "    batchMax = max(sample)#67199\n",
    "    #     batchMax  = 69050\n",
    "    #print(\"batch min \" , batchMin,\" batch max \", batchMax )\n",
    "    remMin = batchMin % BATCHSIZE_Y\n",
    "    multipleMin = int(batchMin / BATCHSIZE_Y)\n",
    "\n",
    "    remMax = batchMax % BATCHSIZE_Y\n",
    "    multipleMax = int(batchMax / BATCHSIZE_Y)\n",
    "    \n",
    "    batch = None\n",
    "    if(multipleMin != multipleMax):# have to concatenate  batch size can never be more than 3000#\n",
    "        print('here')\n",
    "        batch = np.concatenate((outputsData[multipleMin],outputsData[multipleMax]), axis = 0)\n",
    "    else:\n",
    "        print('not here')\n",
    "        batch = outputsData[multipleMin]\n",
    "\n",
    "    offset = multipleMin*BATCHSIZE_Y\n",
    "    sample_ = np.array(sample)-offset\n",
    "    data_output = batch[sample_]\n",
    "    return data_output\n",
    "\n",
    "\n",
    "output_images = calculateOutput(sample)\n",
    "output_images.shape\n",
    "#( numLayers, 256, 256) to (256, 256, numLayers) \n",
    "#testDataT = transpose3dImage(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-25a97c386e78>:11: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.140359,\n",
       " 3.24087,\n",
       " 15.307369,\n",
       " -15.310234,\n",
       " 6.9300766,\n",
       " 9.067983,\n",
       " -29.766876,\n",
       " 6.4712744,\n",
       " 27.031092,\n",
       " 17.86364]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = .008\n",
    "costs = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    X, Y = create_placeholders(64, 64, 3, 35)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_prop(X, parameters)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#1e-4).minimize(cross_entropy)\n",
    "    #init must be after optimizer\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        _ , temp_cost = sess.run([optimizer,cost], feed_dict={X: np.random.randn(2,64,64,3), Y: np.random.randn(2,35)})\n",
    "        costs.append(temp_cost)\n",
    "        \n",
    "        \n",
    "    #     a = sess.run(cost, {X: np.random.randn(2,64,64,3), Y: np.random.randn(2,35)})\n",
    "    #     print(\"Z3 = \" + str(a))\n",
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zipLoc = cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\New folder\\drive-download-20181203T055115Z-005.zip')\n",
    "# directory = cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\New folder\\\\')+'/'\n",
    "\n",
    "# print(zipLoc)\n",
    "# print(directory)\n",
    "# with zipfile.ZipFile(zipLoc, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(directory)\n",
    "# a = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\New folder\\x__buildings_.npy'))\n",
    "# #b = cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\New folder\\y__c16_.npy')\n",
    "# #a = np.load(b)\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]),)\n",
      "(array([0]),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammadayub/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:40: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "/home/muhammadayub/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:41: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "# inputImage, output_image, waterway = generateMinibatch(minibatches[10])\n",
    "#inputImage, output_image = generateMinibatch(minibatches[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting  2018-12-07 10:46:58.270191\n",
      "[1. 1. 1.]   [-1. -1. -1. -1. -1.]\n",
      "Minibatch End:  2018-12-07 10:46:58.274927\n",
      "[2. 2. 2.]   [-2. -2. -2. -2. -2.]\n",
      "Minibatch End:  2018-12-07 10:46:58.281954\n",
      "[3. 3. 3.]   [-3. -3. -3. -3. -3.]\n",
      "Minibatch End:  2018-12-07 10:46:58.282827\n",
      "[4. 4. 4.]   [-4. -4. -4. -4. -4.]\n",
      "Minibatch End:  2018-12-07 10:46:58.307993\n",
      "[5. 5. 5.]   [-5. -5. -5. -5. -5.]\n",
      "Minibatch End:  2018-12-07 10:46:58.309239\n",
      "[6. 6. 6.]   [-6. -6. -6. -6. -6.]\n",
      "Minibatch End:  2018-12-07 10:46:58.317652\n",
      "[7. 7. 7.]   [-7. -7. -7. -7. -7.]\n",
      "Minibatch End:  2018-12-07 10:46:58.318579\n",
      "[8. 8. 8.]   [-8. -8. -8. -8. -8.]\n",
      "Minibatch End:  2018-12-07 10:46:58.351404\n",
      "[9. 9. 9.]   [-9. -9. -9. -9. -9.]\n",
      "Minibatch End:  2018-12-07 10:46:58.352740\n",
      "[10. 10. 10.]   [-10. -10. -10. -10. -10.]\n",
      "Minibatch End:  2018-12-07 10:46:58.359940\n",
      "[11. 11. 11.]   [-11. -11. -11. -11. -11.]\n",
      "Minibatch End:  2018-12-07 10:46:58.361348\n",
      "[12. 12. 12.]   [-12. -12. -12. -12. -12.]\n",
      "Minibatch End:  2018-12-07 10:46:58.368089\n",
      "[13. 13. 13.]   [-13. -13. -13. -13. -13.]\n",
      "Minibatch End:  2018-12-07 10:46:58.369006\n",
      "[14. 14. 14.]   [-14. -14. -14. -14. -14.]\n",
      "Minibatch End:  2018-12-07 10:46:58.378362\n",
      "[15. 15. 15.]   [-15. -15. -15. -15. -15.]\n",
      "Minibatch End:  2018-12-07 10:46:58.379916\n",
      "[16. 16. 16.]   [-16. -16. -16. -16. -16.]\n",
      "Minibatch End:  2018-12-07 10:46:58.387315\n",
      "[17. 17. 17.]   [-17. -17. -17. -17. -17.]\n",
      "Minibatch End:  2018-12-07 10:46:58.388241\n",
      "[18. 18. 18.]   [-18. -18. -18. -18. -18.]\n",
      "Minibatch End:  2018-12-07 10:46:58.394665\n",
      "[19. 19. 19.]   [-19. -19. -19. -19. -19.]\n",
      "Minibatch End:  2018-12-07 10:46:58.395538\n",
      "[20. 20. 20.]   [-20. -20. -20. -20. -20.]\n",
      "Minibatch End:  2018-12-07 10:46:58.401902\n",
      "[21. 21. 21.]   [-21. -21. -21. -21. -21.]\n",
      "Minibatch End:  2018-12-07 10:46:58.402781\n",
      "[22. 22. 22.]   [-22. -22. -22. -22. -22.]\n",
      "Minibatch End:  2018-12-07 10:46:58.409561\n",
      "[23. 23. 23.]   [-23. -23. -23. -23. -23.]\n",
      "Minibatch End:  2018-12-07 10:46:58.410423\n",
      "[24. 24. 24.]   [-24. -24. -24. -24. -24.]\n",
      "Minibatch End:  2018-12-07 10:46:58.417281\n",
      "[25. 25. 25.]   [-25. -25. -25. -25. -25.]\n",
      "Minibatch End:  2018-12-07 10:46:58.418187\n",
      "[26. 26. 26.]   [-26. -26. -26. -26. -26.]\n",
      "Minibatch End:  2018-12-07 10:46:58.424356\n",
      "[27. 27. 27.]   [-27. -27. -27. -27. -27.]\n",
      "Minibatch End:  2018-12-07 10:46:58.425419\n",
      "[28. 28. 28.]   [-28. -28. -28. -28. -28.]\n",
      "Minibatch End:  2018-12-07 10:46:58.431661\n",
      "[29. 29. 29.]   [-29. -29. -29. -29. -29.]\n",
      "Minibatch End:  2018-12-07 10:46:58.432437\n",
      "[30. 30. 30.]   [-30. -30. -30. -30. -30.]\n",
      "Minibatch End:  2018-12-07 10:46:58.438680\n",
      "Epoch End:  2018-12-07 10:46:58.438730\n"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "learning_rate = .008\n",
    "costs = []\n",
    "num_epochs = 1\n",
    "\n",
    "WaterWayMask = generateWaterWayMask(waterway, 400)\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(): # https://stackoverflow.com/questions/36281129/no-variable-to-save-error-in-tensorflow\n",
    "\n",
    "    #variable declarations must be before tf.train.Saver() unless here: https://stackoverflow.com/questions/50974976/tensorflow-why-must-saver-tf-train-saver-be-declared-after-variables-are\n",
    "    #the model\n",
    "#     X, Y = create_placeholders(64, 64, 26, 34)\n",
    "#     parameters = initialize_parameters()\n",
    "#     Z3 = forward_prop(X, parameters)\n",
    "\n",
    "#     cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "#     optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#1e-4).minimize(cross_entropy)\n",
    "    v1 = tf.get_variable(\"v1\", shape=[3], initializer = tf.zeros_initializer)\n",
    "    v2 = tf.get_variable(\"v2\", shape=[5], initializer = tf.zeros_initializer)\n",
    "\n",
    "    inc_v1 = v1.assign(v1+1)\n",
    "    dec_v2 = v2.assign(v2-1)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # # Initialize all the variables globally\n",
    "    # init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "\n",
    "        #init must be after optimizer\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        print('Starting ' , datetime.datetime.now())\n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            np.random.shuffle(minibatches) # get new minibatch results \n",
    "\n",
    "            for i_ , minibatch in enumerate(minibatches[:30]):\n",
    "\n",
    "                # Select a minibatch\n",
    "#                 inputImage, output_image = generateMinibatch(minibatches[10])\n",
    "#                 inputImage64, output_image64 = transformTo64(inputImage, output_image,34)\n",
    "#                 output_image64 = output_image64[WaterWayMask]\n",
    "#                 inputImage64 = inputImage64[WaterWayMask]\n",
    "    \n",
    "                a = sess.run(inc_v1)\n",
    "                b= sess.run(dec_v2)\n",
    "                print(a , \" \", b)\n",
    "\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "#                 _ , temp_cost = sess.run([optimizer,cost], feed_dict={X: inputImage64, Y: output_image64})\n",
    "                ### END CODE HERE ###\n",
    "\n",
    "#                 minibatch_cost += temp_cost / MINIBATCHES_AMT\n",
    "\n",
    "                print('Minibatch End: ', datetime.datetime.now())\n",
    "\n",
    "                if(i_ % 2 == 0 ):\n",
    "                    #save model\n",
    "                    save_path = saver.save(sess, \"/home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__\"+str(epoch)+\"_\"+str(i_)+\".ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "            costs.append(minibatch_cost)\n",
    "            print('Epoch End: ', datetime.datetime.now())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__0_28.ckpt\n",
      "Model restored.\n",
      "v1 : [29. 29. 29.]\n",
      "v2 : [-29. -29. -29. -29. -29.]\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default(): \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        #define the graph\n",
    "#         X, Y = create_placeholders(64, 64, 26, 34)\n",
    "#         parameters = initialize_parameters()\n",
    "#         Z3 = forward_prop(X, parameters)\n",
    "\n",
    "#         cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "#         optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#1e-4).minimize(cross_entropy)\n",
    "        v1 = tf.get_variable(\"v1\", shape=[3])\n",
    "        v2 = tf.get_variable(\"v2\", shape=[5])\n",
    "\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "#         saver.restore(sess, \"/home/muhammadayub/Desktop/CS230/models_saved/model_12_7__0_2.ckpt\")\n",
    "        saver.restore(sess , \"/home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__\"+str(0)+\"_\"+str(28)+\".ckpt\")\n",
    "        print(\"Model restored.\")\n",
    "#         temp_cost = sess.run([cost], feed_dict={X: inputImage64, Y: output_image64})\n",
    "#         print(temp_cost)\n",
    "        print(\"v1 : %s\" % v1.eval())\n",
    "        print(\"v2 : %s\" % v2.eval())\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting  2018-12-07 11:27:17.292305\n",
      "Minibatch End:  2018-12-07 11:27:27.506599\n",
      "3.5461538   0   0\n",
      "3.5461538  at file name:  p/CS230/models_saved/model1/model_12_7__0_0.ckpt\n",
      "Minibatch End:  2018-12-07 11:27:37.662254\n",
      "0.2665895   0   1\n",
      "Minibatch End:  2018-12-07 11:27:47.855061\n",
      "2.1674415e-08   0   2\n",
      "2.1674415e-08  at file name:  p/CS230/models_saved/model1/model_12_7__0_2.ckpt\n",
      "Minibatch End:  2018-12-07 11:27:57.999561\n",
      "0.0   0   3\n",
      "Epoch End:  2018-12-07 11:27:57.999767\n"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "learning_rate = .008\n",
    "costs = []\n",
    "num_epochs = 1\n",
    "\n",
    "WaterWayMask = generateWaterWayMask(waterway, 400)\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(): # https://stackoverflow.com/questions/36281129/no-variable-to-save-error-in-tensorflow\n",
    "\n",
    "    #variable declarations must be before tf.train.Saver() unless here: https://stackoverflow.com/questions/50974976/tensorflow-why-must-saver-tf-train-saver-be-declared-after-variables-are\n",
    "    #the model\n",
    "    X, Y = create_placeholders(64, 64, 26, 34)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_prop(X, parameters)\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#1e-4).minimize(cross_entropy)\n",
    "\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # # Initialize all the variables globally\n",
    "    # init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "\n",
    "        #init must be after optimizer\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        print('Starting ' , datetime.datetime.now())\n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            np.random.shuffle(minibatches) # get new minibatch results \n",
    "\n",
    "            for i_ , minibatch in enumerate(minibatches[:4]):\n",
    "\n",
    "                # Select a minibatch\n",
    "                inputImage, output_image = generateMinibatch(minibatches[10])\n",
    "                inputImage64, output_image64 = transformTo64(inputImage, output_image,34)\n",
    "                output_image64 = output_image64[WaterWayMask]\n",
    "                inputImage64 = inputImage64[WaterWayMask]\n",
    "\n",
    "\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , temp_cost = sess.run([optimizer,cost], feed_dict={X: inputImage64, Y: output_image64})\n",
    "                ### END CODE HERE ###\n",
    "\n",
    "                minibatch_cost += temp_cost / MINIBATCHES_AMT\n",
    "\n",
    "                print('Minibatch End: ', datetime.datetime.now())\n",
    "                print(temp_cost,' ' , epoch,' ' ,i_)\n",
    "                if((epoch ==0) and (i_==0)):\n",
    "                    globalA = inputImage64\n",
    "                    globalB = output_image64\n",
    "                \n",
    "                if(i_ % 2 == 0 ):\n",
    "                    #save model\n",
    "                    filepath = \"/home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__\"+str(epoch)+\"_\"+str(i_)+\".ckpt\"\n",
    "                    print(temp_cost, \" at file name: \", filepath[25:])\n",
    "                    save_path = saver.save(sess, filepath)\n",
    "\n",
    "            costs.append(minibatch_cost)\n",
    "            print('Epoch End: ', datetime.datetime.now())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restoring the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__0_0.ckpt\n",
      "Model restored.\n",
      "[0.2665895]\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default(): \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        #define the graph\n",
    "        X, Y = create_placeholders(64, 64, 26, 34)\n",
    "        parameters = initialize_parameters()\n",
    "        Z3 = forward_prop(X, parameters)\n",
    "\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#1e-4).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        filepath = \"/home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__\"+str(0)+\"_\"+str(0)+\".ckpt\"\n",
    "        saver.restore(sess , filepath)\n",
    "        print(\"Model restored.\")\n",
    "#         temp_cost = sess.run([cost], feed_dict={X: inputImage64, Y: output_image64})\n",
    "        temp_cost = sess.run([cost], feed_dict={X: globalA, Y: globalB})\n",
    "        print(temp_cost)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__0_0.ckpt\n",
      "Model restored.\n",
      "1\n",
      "(2200, 34)\n",
      "(2200, 34)\n",
      "[  4.969107    -4.984261    -5.4040246   -3.5773609   -2.5310621\n",
      "  -5.2351933   -0.28978592   1.0503783   -4.4019074    0.24583222\n",
      "   2.7867198   -0.17608412  -3.7381537   -0.36514688  -5.528918\n",
      "   0.32078913  -0.3304461  -10.258598     0.17988376   0.96249914\n",
      "  -6.880415    -4.535321    -0.8508476    2.2087934   -4.1368647\n",
      "  -3.213399     0.42857364  -7.867529    -7.1727014   -4.282679\n",
      "  -4.5996165   -3.9495633   -0.09596492  -2.784913  ]\n",
      "[7.7879632e-01 3.7045120e-05 2.4346135e-05 1.5126556e-04 4.3066716e-04\n",
      " 2.8823899e-05 4.0505654e-03 1.5471826e-02 6.6319910e-05 6.9204089e-03\n",
      " 8.7826401e-02 4.5383265e-03 1.2879779e-04 3.7565287e-03 2.1487684e-05\n",
      " 7.4590775e-03 3.8891716e-03 1.8972109e-07 6.4787418e-03 1.4170204e-02\n",
      " 5.5621413e-06 5.8036723e-05 2.3112642e-03 4.9275935e-02 8.6447086e-05\n",
      " 2.1767394e-04 8.3079757e-03 2.0727355e-06 4.1524409e-06 7.4717820e-05\n",
      " 5.4422690e-05 1.0425441e-04 4.9168961e-03 3.3411477e-04]\n",
      "(2200,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.27122808]\n",
      "num_correct_val:  [ True  True  True  True  True  True  True  True  True  True False  True]\n",
      "[array([0, 0, 0, ..., 0, 0, 0])]\n",
      "num_correct_to_int_val  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "accuracy_val  [0.99954545]\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default(): \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        #define the graph\n",
    "        X, Y = create_placeholders(64, 64, 26, 34)\n",
    "        parameters = initialize_parameters()\n",
    "        Z3 = forward_prop(X, parameters)\n",
    "\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#1e-4).minimize(cross_entropy)\n",
    "\n",
    "        #calculating the accuracy of the model \n",
    "        softmaxZ3 = tf.nn.softmax(Z3) # size will be 2200, 34\n",
    "        output_class = tf.argmax(softmaxZ3,1) # size will be 2200, 1 or just (2200,)\n",
    "        num_correct = tf.equal(output_class, tf.argmax(Y,1)) # must compare 2200\n",
    "        num_correct_to_int = tf.cast(num_correct, tf.float32)\n",
    "        accuracy = tf.reduce_mean(num_correct_to_int)\n",
    "        \n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        filepath = \"/home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__\"+str(0)+\"_\"+str(0)+\".ckpt\"\n",
    "        saver.restore(sess , filepath)\n",
    "        print(\"Model restored.\")\n",
    "#         temp_cost = sess.run([cost], feed_dict={X: inputImage64, Y: output_image64})\n",
    "        temp_cost = sess.run([cost], feed_dict={X: globalA, Y: globalB})\n",
    "        zVal = sess.run([Z3], feed_dict={X: globalA, Y: globalB})\n",
    "        softMaxVal = sess.run([softmaxZ3], feed_dict={X: globalA, Y: globalB})\n",
    "        output_class_val = sess.run([output_class], feed_dict={X: globalA, Y: globalB})\n",
    "        num_correct_val = sess.run([num_correct], feed_dict={X: globalA, Y: globalB})\n",
    "        num_correct_to_int_val = sess.run([num_correct_to_int], feed_dict={X: globalA, Y: globalB})\n",
    "        accuracy_val = sess.run([accuracy], feed_dict={X: globalA, Y: globalB})\n",
    "        \n",
    "        random = sess.run([tf.argmax(Y,1)], feed_dict={X: globalA, Y: globalB})\n",
    "        \n",
    "        print(len(zVal))\n",
    "        print(zVal[0].shape)\n",
    "        print(softMaxVal[0].shape)\n",
    "        print(zVal[0][0])\n",
    "        print(softMaxVal[0][0])\n",
    "        print(output_class_val[0].shape)\n",
    "        print(output_class_val[0])\n",
    "        print(temp_cost)\n",
    "        print('num_correct_val: ', num_correct_val[0][:12])\n",
    "        print(random)\n",
    "        print('num_correct_to_int_val ', num_correct_to_int_val[0][:12])\n",
    "        print('accuracy_val ', accuracy_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 34)\n",
      "0.9995454545454545\n"
     ]
    }
   ],
   "source": [
    "print(globalB.shape)\n",
    "set(np.where(globalB == 1)[1].tolist())  \n",
    "globalB[10][0] = 0\n",
    "globalB[10][5] = 1\n",
    "globalB[:12]\n",
    "print(2199/2200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__0_0.ckpt\n",
      "Model restored.\n",
      "1\n",
      "(2200, 34)\n",
      "[0.2665895]\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default(): \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        #define the graph\n",
    "        X, Y = create_placeholders(64, 64, 26, 34)\n",
    "        parameters = initialize_parameters()\n",
    "        Z3 = forward_prop(X, parameters)\n",
    "\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#1e-4).minimize(cross_entropy)\n",
    "\n",
    "        softmaxZ3 = tf.nn.softmax(Z3)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        filepath = \"/home/muhammadayub/Desktop/CS230/models_saved/model1/model_12_7__\"+str(0)+\"_\"+str(0)+\".ckpt\"\n",
    "        saver.restore(sess , filepath)\n",
    "        print(\"Model restored.\")\n",
    "#         temp_cost = sess.run([cost], feed_dict={X: inputImage64, Y: output_image64})\n",
    "        temp_cost = sess.run([cost], feed_dict={X: globalA, Y: globalB})\n",
    "        zVal = sess.run([Z3], feed_dict={X: globalA, Y: globalB})\n",
    "        print(len(zVal))\n",
    "        print(zVal[0].shape)\n",
    "        \n",
    "        print(temp_cost)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
