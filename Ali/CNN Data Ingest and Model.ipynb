{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/muhammadayub/Desktop/CS230/Notebooks/re'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanURL(url):\n",
    "    p = pathlib.Path(url)\n",
    "    path = str(p.as_posix()) \n",
    "    return path \n",
    "\n",
    "\n",
    "def getDF(loc, sheetname):\n",
    "    dataframe = pd.read_excel(loc, sheetname)\n",
    "    #https://stackoverflow.com/questions/40950310/strip-trim-all-strings-of-a-dataframe\n",
    "    dataframe = dataframe.applymap(lambda x: x.strip() if type(x) is str else x)\n",
    "    return dataframe\n",
    "\n",
    "def printNulls(df):\n",
    "    null_columns = df.columns[df.isnull().any()]\n",
    "    return df[null_columns].isnull().sum() \n",
    "\n",
    "\n",
    "def writeDFToFile(dfs, path_): #dfs is an array of dataframes and their sheet names , path needs to have\n",
    "    time_ = str(datetime.datetime.now())\n",
    "    current_date_time = time_[0:time_.index(\".\")]\n",
    "    current_date_time = current_date_time.replace(\":\", \"-\")\n",
    "    task4_fileoutput = path_+current_date_time+\".xlsx\"\n",
    "\n",
    "    writer = pd.ExcelWriter(task4_fileoutput)\n",
    "    \n",
    "    for df_tuple in dfs:  \n",
    "        df = df_tuple[0]\n",
    "        sheetName = df_tuple[1]\n",
    "        df.to_excel(writer, sheetName)\n",
    "    print(\"file written to :       \" + task4_fileoutput)\n",
    "    writer.save()\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the data loader methodology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# Constants \n",
    "################\n",
    "BATCHSIZE_Y = 3000\n",
    "LAST_BATCHSIZE_Y = 3000\n",
    "TIMES_OF_DAY = 24\n",
    "#The last day since the LEntries data only goes to 6/20/2018, we should filter to that end \n",
    "LAST_DAY = 6350 # in terms of timedelta.days\n",
    "#FIRST_DAY was 1/1/2001, last day should then be 6/30/2018\n",
    "MINIBATCHES_AMT = 762 #or (200,762) (254 batches of 600) (gcf of 3000 and 152400) # keep in mind that this number is going to be scaled by 16 since 16 64by64 images are in one 256by256\n",
    "#150 or 1016              #batch size should never be more than 2900 (really 3000, but to stay on the safe side)\n",
    "iHeight = 256\n",
    "iWidth = 256\n",
    "\n",
    "\n",
    "################\n",
    "# Load all the data , for the larger data values , just run  \n",
    "################\n",
    "\n",
    "# load all the data #CHANGEME\n",
    "# datesb = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\dates_data_b.npy'))\n",
    "# dates = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\dates_data.npy'))\n",
    "# buildings = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\x__buildings_b.npy'))\n",
    "datesb = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/dates_data_b.npy'))\n",
    "dates = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/dates_data.npy'))\n",
    "buildings = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/x__buildings_b.npy'))\n",
    "\n",
    "\n",
    "\n",
    "#make sure there are no nan values in buildings \n",
    "mask = np.isnan(buildings)\n",
    "indices = np.where(mask ==True)\n",
    "z = indices[0]\n",
    "y = indices[1]\n",
    "x = indices[2]\n",
    "buildings[z,y,x] = -1\n",
    "\n",
    "# businesses = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\x__businesses_b.npy'))\n",
    "# socio = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\x__socio_b.npy'))\n",
    "# lentries = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\x__Lentries_c.npy'), mmap_mode  = 'r')\n",
    "# waterway = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\waterway.npy'))\n",
    "businesses = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/x__businesses_b.npy'))\n",
    "socio = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/x__socio_b.npy'))\n",
    "lentries = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/x__Lentries_c.npy'))#, mmap_mode  = 'r')#CHANGEME\n",
    "waterway = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/waterway.npy'))\n",
    "##KLUDGE: This is a quick fix, just set a lot of the data to 0\n",
    "waterway[:,170:]= 1\n",
    "\n",
    "#get all the masks used\n",
    "\n",
    "################\n",
    "# Preprocess every image value to be its transpose\n",
    "################\n",
    "# buildings  buildingsT -> buildingsTStacked\n",
    "# businesses    businessesT -> businessesTStacked\n",
    "# socio   socioT -> socioTStacked\n",
    "buildingsT= transpose3dImage(buildings)\n",
    "businessesT= transpose3dImage(businesses)\n",
    "socioT = transpose3dImage(socio)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load all the outputs\n",
    "outputsData =[]\n",
    "for i_ in range(1, 53):\n",
    "    y_ = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\y__c'+str(i_)+'_c.npy'), mmap_mode  = 'r')\n",
    "    outputsData.append(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we have enough RAM ( 40 GB worth after we have added everything else) , combine every output to one big ndarray \n",
    "# this results in huge speed up\n",
    "# if at all possible  #CHANGEME\n",
    "outputsDataReal = np.concatenate(outputsData, axis = 0)\n",
    "print(outputsDataReal.shape)\n",
    "for i_ in range(len(outputsData)):\n",
    "    outputsData[i_] =None\n",
    "    \n",
    "# if at all possible  #CHANGEME\n",
    "for i_ in range(len(outputsDataReal)):\n",
    "    outputsDataReal[i_] =outputsDataReal[i_].T\n",
    "print('run once')\n",
    "# print(outputsDataReal.max())#33 is max, 0 is min\n",
    "# print(outputsDataReal.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# waterway was not working, for the time being, simply remove right portion of the images\n",
    "waterway = np.load(cleanURL(r'/home/muhammadayub/Desktop/CS230/training_data/waterway.npy'))\n",
    "# waterway2=np.array(waterway)\n",
    "waterway[:,170:]= 1\n",
    "plotImg(waterway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to print the waterway mask\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plotImg(img):\n",
    "    if(type(img) ==type(None)):\n",
    "        img =outputsDataReal[10000]\n",
    "    arr = []\n",
    "    for a in img:\n",
    "        arr = [a] + arr\n",
    "    plt.pcolor( arr, cmap = 'gist_ncar' )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4833"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### outputs are very sparse\n",
    "abc = np.where(outputsDataReal[1000:10000] !=0)\n",
    "# plotImg(outputsDataReal[1000])\n",
    "len(abc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the data (to align all the indices of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lentries.shape\n",
    "print(len(lentries)*24)\n",
    "print(len(lentries))\n",
    "# len of everything \n",
    "print('number of outputs ' , BATCHSIZE_Y*51+len(outputsData[-1])) # number of outputs , wont work if you combine outputsData to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data points 152400\n",
      "will shave off extra data. Everything starts from the same point in time\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculate the exact value of how many (256 by 256 by numlayer) images we should have \n",
    "indices = LAST_DAY* TIMES_OF_DAY\n",
    "indices_ = np.array([index for index in range(indices)])\n",
    "print('Actual data points', len(indices_)) # 0 - 153,335 or 153,336 values                      #152400\n",
    "print(\"will shave off extra data. Everything starts from the same point in time\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate minibatches. Shuffle the minibatches, have a function to return a minibatch of X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762\n",
      "685 38 39\n"
     ]
    }
   ],
   "source": [
    "#get the split of the train/dev/test -> 90, 5, 5\n",
    "print(MINIBATCHES_AMT)\n",
    "train_split = int(MINIBATCHES_AMT*.90)\n",
    "dev_split = int(MINIBATCHES_AMT*.05)\n",
    "test_split = MINIBATCHES_AMT - train_split - dev_split\n",
    "\n",
    "print(train_split, dev_split, test_split)\n",
    "assert(train_split + dev_split + test_split == len(MINIBATCHES_AMT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of datapoints [     0      1      2 ... 152397 152398 152399]\n"
     ]
    }
   ],
   "source": [
    "print('Indices of datapoints', indices_)\n",
    "#gets the indices of the minibatches\n",
    "\n",
    "minibatches = np.split(indices_,MINIBATCHES_AMT)\n",
    "\n",
    "devMiniBatches = minibatches[train_split:train_split+dev_split]\n",
    "testMiniBatches = minibatches[train_split+dev_split:]\n",
    "minibatches = minibatches[:train_split] #training set  #must be at the end\n",
    "\n",
    "# sample = np.array(minibatches[0])\n",
    "# print('sample minibatch: ' , sample )\n",
    "# #to shuffle the minibatches for random minibatches  we will do this every epoch\n",
    "# np.random.shuffle(minibatches)\n",
    "# print(devMiniBatches)\n",
    "# print(testMiniBatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# datesb -- no need \n",
    "# dates -- no need\n",
    "# buildings  buildingsT -> buildingsTStacked\n",
    "# businesses    businessesT -> businessesTStacked\n",
    "# socio   socioT -> socioTStacked\n",
    "# lentries \n",
    "# waterway  -- not part of data \n",
    "# outputsData \n",
    "\n",
    "\n",
    "#next steps -> add lentries, temperature, and masks \n",
    "\n",
    "# now we write a function that will return to us the correct minibatch , with all the image data generated\n",
    "def generateMinibatch(minibatchIndices):    #everything must be transposed\n",
    "    #general steps:\n",
    "    #get the x inputs\n",
    "    #    same as the file of text \n",
    "    \n",
    "    #step 1. dates (make 12 layers of month, day, year , timeOfDay)  # dateLayers don't need to be transposed -> just 1 value\n",
    "    dateLayers = generateDatesLayers(minibatchIndices, datesb) # (150, 256, 256, 4)  => len(minibatchIndices) = 150\n",
    "    \n",
    "    #step 2. Buildings 10 layers \n",
    "    buildingLayers = stackManyTimes(buildingsT, len(minibatchIndices))  # buildingsT should be (256,256,10) and result should (150, 256, 256, 10)\n",
    "  \n",
    "    #step 3. \n",
    "    businessesLayers = stackManyTimes(businessesT, len(minibatchIndices))\n",
    "    \n",
    "    #step 4. L entries\n",
    "    #come back to this one   => must be transposed!!!\n",
    "    LentryLayers = None\n",
    "    \n",
    "    #step 5. socio\n",
    "    socioLayers = stackManyTimes(socioT, len(minibatchIndices))\n",
    "    \n",
    "    #step 6. temperature #should be format of\n",
    "    #pass on this for now -> will add this for later iterations\n",
    "    \n",
    "    #step 7. concat everything\n",
    "    inputImage = np.concatenate((dateLayers,buildingLayers,businessesLayers,socioLayers) , axis = -1)\n",
    "    #     print(np.where((inputImage[:4]==dateLayers)==False))\n",
    "    #     print(np.where((inputImage[4:14]==buildingLayers)==False))\n",
    "\n",
    "    #step 7. outputs\n",
    "    output_image = outputsDataReal[minibatchIndices]  # calculateOutput(minibatchIndices)\n",
    "    return inputImage, output_image#, waterway\n",
    "\n",
    "def generateDatesLayers(minibatchIndices, datesb):  # makes (n , 256, 256, 4) -> n 4 layer images\n",
    "    base_img_mask = np.ones((256, 256), dtype=np.float32)\n",
    "    xy = np.dstack([base_img_mask]*4) # shape (256, 256, 4)\n",
    "    dateLayers = datesb[minibatchIndices] # (len(minibatchIndices) , 4)\n",
    "    dateLayersReshaped = dateLayers.reshape((len(dateLayers), 1,1,dateLayers.shape[1])) # (len(minibatchIndices),1,1 , 4)\n",
    "    xyz = xy* dateLayersReshaped \n",
    "    return xyz\n",
    "\n",
    "def transpose3dImage(img):  #transpose an image \n",
    "    img_T = img.T #tested this actually does what we wante it to do.  \n",
    "    return img_T\n",
    "\n",
    "\n",
    "def stackManyTimes(_3dimg,times):  # stacks a 3d image \"times\" times\n",
    "    _3dimg_shape = _3dimg.shape\n",
    "    result = np.zeros(shape=(times, _3dimg_shape[0], _3dimg_shape[1],_3dimg_shape[2] ), dtype=np.float32)\n",
    "    for x in range(times):\n",
    "        result[x] = _3dimg\n",
    "    return result\n",
    "\n",
    "def calculateOutput(sample):  #returns the output image (n, 256,256)\n",
    "    batchMin = min(sample)#67050\n",
    "    batchMax = max(sample)#67199\n",
    "    #     batchMax  = 69050\n",
    "    #print(\"batch min \" , batchMin,\" batch max \", batchMax )\n",
    "    remMin = batchMin % BATCHSIZE_Y\n",
    "    multipleMin = int(batchMin / BATCHSIZE_Y)\n",
    "\n",
    "    remMax = batchMax % BATCHSIZE_Y\n",
    "    multipleMax = int(batchMax / BATCHSIZE_Y)\n",
    "    \n",
    "    batch = None\n",
    "    if(multipleMin != multipleMax):# have to concatenate  batch size can never be more than 3000#\n",
    "        print('here')\n",
    "        batch = np.concatenate((outputsData[multipleMin],outputsData[multipleMax]), axis = 0)\n",
    "    else:\n",
    "        print('not here')\n",
    "        batch = outputsData[multipleMin]\n",
    "\n",
    "    offset = multipleMin*BATCHSIZE_Y\n",
    "    sample_ = np.array(sample)-offset\n",
    "    data_output = batch[sample_]\n",
    "    return data_output\n",
    "\n",
    "def splitWaterWay(waterwayImg):  # this will make waterway image into (16,64,64)\n",
    "    imagesList = np.split(waterwayImg, 4, axis = 0)\n",
    "    images64by64 = []\n",
    "\n",
    "    for almostImage in imagesList:\n",
    "        imagesList64by64 = np.split(almostImage, 4, axis = 1) # axis is 0, 1, 2\n",
    "        for actual64by64 in imagesList64by64:\n",
    "            images64by64.append(actual64by64)\n",
    "    #     for i,_64 in enumerate(images64by64):\n",
    "    #         print(i, _64.shape)\n",
    "    return np.concatenate(images64by64, axis = 0)\n",
    "\n",
    "def split256by256StackOnAxis(inputImg):  #returns the images in (64 , 64, numberOfChannels)\n",
    "    imagesList = np.split(inputImg, 4, axis = 1)\n",
    "    images64by64 = []\n",
    "\n",
    "    for almostImage in imagesList:\n",
    "        imagesList64by64 = np.split(almostImage, 4, axis = 2) # axis is 0, 1, 2\n",
    "        for actual64by64 in imagesList64by64:\n",
    "            images64by64.append(actual64by64)\n",
    "    #     for i,_64 in enumerate(images64by64):\n",
    "    #         print(i, _64.shape)\n",
    "    return np.concatenate(images64by64, axis = 0)\n",
    "\n",
    "def getOutputYVector(y_output_image64, numCats): # y_output_image64 is of shape (3200,64,64)  , 34 categories + -1\n",
    "    result = np.zeros((len(y_output_image64), numCats), dtype=np.float32)\n",
    "    cCount = None \n",
    "    for i_, img in enumerate(y_output_image64):\n",
    "        cCount = Counter(img.flatten())\n",
    "        result[i_][int(cCount.most_common()[0][0])] = 1\n",
    "        #get the argmax for now  -1 goes to 0, 0 goes to 1, etc. until you have 33 going to 34   -> kludge need to set this to -1\n",
    "#         result[i_][int(cCount.most_common()[0][0])+1] = 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def transformTo64(inputImage, output_image, numCats): # helper method to turn inputData and outputData (256by256) into the 64by64 image\n",
    "    inputImage64 =  split256by256StackOnAxis(inputImage)\n",
    "    output_image64 = split256by256StackOnAxis(output_image)\n",
    "    output_image64 = getOutputYVector(output_image64, numCats) #34 categories since we use -1s, but then shave them off\n",
    "    return inputImage64, output_image64\n",
    "\n",
    "def generateWaterWayMask(waterway, threshold):# between 0 and 4096, need atmost 'threshold' to be water \n",
    "    sizeOfOneMiniBatch = int(len(indices_)/MINIBATCHES_AMT)\n",
    "    waterwayMask = np.zeros((sizeOfOneMiniBatch, 256,256), dtype=np.float32)\n",
    "    for i_ in range(len(waterwayMask)):\n",
    "        waterwayMask[i_] = waterway\n",
    "        \n",
    "    #now that we have the ( 200, 256,256)  (sizeOfOneMiniBatch is 200 for example)\n",
    "    #we can break it up into the 64 by 64 images\n",
    "    waterwayMask64 = split256by256StackOnAxis(waterwayMask)\n",
    "    #from here, you count up each one of the 64 by 64 images and set to the threshold\n",
    "    waterwayMaskIndices = [] # include if they are one \n",
    "    for i_ in range(len(waterwayMask64)):\n",
    "        if(np.sum(waterwayMask64[i_]) <= threshold): #> would mean you have more 1's than allowed -> not tolerable \n",
    "            waterwayMaskIndices.append(i_)\n",
    "    return waterwayMaskIndices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition (based off research paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈2 lines)\n",
    "    X = tf.placeholder(shape =[None, n_H0, n_W0, n_C0], dtype = np.float32, name=\"X\")\n",
    "    Y = tf.placeholder(shape  =[None, n_y], dtype = np.float32 , name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X_1:0\", shape=(?, 64, 64, 26), dtype=float32)\n",
      "Y = Tensor(\"Y_1:0\", shape=(?, 34), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(64, 64, 26, 34)  #will have 35 , 34 real values and 1 fake value\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First CNN Trial\n",
    "\n",
    "### First filter shape: (10 , 10,3 , 3) stride = 2, valid padding\n",
    "    \n",
    "    (64 +2p - f)/s +1 => (64+0-10)/2+1 = 28\n",
    "    So, (?, 64, 64, 3) * (10 , 10 , 3,  3) = (?, 28, 28, 3 )\n",
    "    \n",
    "### Average Pooling Layer: (3 , 3 , 3) stride = 1, Padding = SAME\n",
    "    \n",
    "    (28 +2p - f)/s +1 => (28+2*1-3)/1+1 = 28\n",
    "    So, (?, 28, 28, 3) * ( 3 , 3,  3) = (?, 28, 28, 3 )\n",
    "    \n",
    "    \n",
    "### Second filter shape: (6 , 6 ,3, 2) stride = 2, valid padding\n",
    "    \n",
    "    (28 +2p - f)/s +1 => (28+0-6)/2+1 = 12\n",
    "    So, (?, 28, 28, 3) * (6 , 6 , 3, 2) = (?, 12, 12, 2)\n",
    "    \n",
    "### Max Pooling layer valid padding stride 1 (3,3)\n",
    "    \n",
    "    (12 +2p - f)/s +1 => (12+0-3)/1+1 = 10\n",
    "    So, (?, 12,12, 2) * (3, 3 , 2, 2) = (?, 10, 10, 2)\n",
    "\n",
    "    \n",
    "### Fourth filter shape: Flatten , fully connected (10*10*2) = 200\n",
    "    \n",
    "    W3 = 36 by 200\n",
    "    \n",
    "### Softmax function for evaluation    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():    \n",
    "\n",
    "    W1 = tf.get_variable(\"W1\", [10, 10, 26, 3], initializer =tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable(\"W2\", [6, 6, 3, 2], initializer =tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W3 = tf.get_variable(\"W3\", [35,200] , initializer =tf.contrib.layers.xavier_initializer(seed = 0) )\n",
    "\n",
    "    parameters = {\"W1\": W1, \"W2\": W2 , 'W3': 'W3'}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_prop(X, params):\n",
    "    W1 = params['W1']\n",
    "    W2 = params['W2']    \n",
    "    W3 = params['W3']\n",
    "    \n",
    "    #convolution \n",
    "    Z1 = tf.nn.conv2d(X,W1, strides = [1,2,2,1], padding = 'VALID')\n",
    "    \n",
    "    #bias added automatically # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    \n",
    "    #average pooling -> at this point all features/weights are important to us\n",
    "    P1 = tf.nn.avg_pool(A1, ksize = [1,3,3,1], strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "    # convolution \n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides = [1,2,2,1], padding = 'VALID')\n",
    "    \n",
    "    #RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    \n",
    "    #max pooling\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,3,3,1], strides = [1,1,1,1], padding = 'VALID')\n",
    "    \n",
    "    #flatten\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "\n",
    "    #fully connected\n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, 34, activation_fn = None) #1 for yes/no\n",
    "    #going to add the softmax directly\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run or Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting  2018-12-06 19:06:21.262765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammadayub/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:40: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "/home/muhammadayub/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:41: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]),)\n",
      "(array([0]),)\n",
      "Minibatch End:  2018-12-06 19:06:32.130429\n",
      "(array([0]),)\n",
      "(array([0]),)\n",
      "Minibatch End:  2018-12-06 19:06:42.969363\n",
      "Epoch End:  2018-12-06 19:06:42.969502\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = .008\n",
    "costs = []\n",
    "num_epochs = 20\n",
    "\n",
    "WaterWayMask = generateWaterWayMask(waterway, 400)# the constants must be called before running this\n",
    "\n",
    "\n",
    "# # Initialize all the variables globally\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "# Start the session to compute the tensorflow graph\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    #the model\n",
    "    X, Y = create_placeholders(64, 64, 26, 34)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_prop(X, parameters)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#1e-4).minimize(cross_entropy)\n",
    "    \n",
    "    #init must be after optimizer\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    \n",
    "    # Run the initialization\n",
    "    sess.run(init)\n",
    "    print('Starting ' , datetime.datetime.now())\n",
    "    # Do the training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        minibatch_cost = 0.\n",
    "        np.random.shuffle(minibatches) # get new minibatch results \n",
    "\n",
    "        for minibatch in minibatches:\n",
    "\n",
    "            # Select a minibatch\n",
    "            inputImage, output_image = generateMinibatch(minibatches[10])\n",
    "            inputImage64, output_image64 = transformTo64(inputImage, output_image,34)\n",
    "            output_image64 = output_image64[WaterWayMask]\n",
    "            inputImage64 = inputImage64[WaterWayMask]\n",
    "            \n",
    "            # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "            # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "            ### START CODE HERE ### (1 line)\n",
    "            _ , temp_cost = sess.run([optimizer,cost], feed_dict={X: inputImage64, Y: output_image64})\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            minibatch_cost += temp_cost / MINIBATCHES_AMT\n",
    "\n",
    "            print('Minibatch End: ', datetime.datetime.now())\n",
    "        \n",
    "        \n",
    "        costs.append(minibatch_cost)\n",
    "        print('Epoch End: ', datetime.datetime.now())\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at data generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-06 18:59:36.103546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammadayub/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:40: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "/home/muhammadayub/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:41: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]),)\n",
      "(array([0]),)\n",
      "2018-12-06 18:59:43.296475\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "WaterWayMask = generateWaterWayMask(waterway, 400)\n",
    "inputImage, output_image = generateMinibatch(minibatches[10])\n",
    "# print(inputImage.dtype)\n",
    "# print(output_image.dtype)\n",
    "inputImage64, output_image64 = transformTo64(inputImage, output_image,34)\n",
    "# print(inputImage64.dtype)\n",
    "# print(output_image64.dtype)\n",
    "output_image64 = output_image64[WaterWayMask]\n",
    "inputImage64 = inputImage64[WaterWayMask]\n",
    "# print(inputImage64.dtype)\n",
    "# print(output_image64.dtype)\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 64, 64, 26)\n",
      "(1600, 34)\n",
      "float64\n",
      "float64\n",
      "1600\n"
     ]
    }
   ],
   "source": [
    "print(inputImage64.shape)\n",
    "print(output_image64.shape)\n",
    "print(inputImage64.dtype)\n",
    "print(output_image64.dtype)\n",
    "print(len(WaterWayMask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For back up testing and everything  --> no need to look at this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 64, 64)\n",
      "(3200, 34)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(output_image.shape)\n",
    "\n",
    "# output = getOutputYVector(output_image,34)\n",
    "# print(output.shape)\n",
    "# output[0]\n",
    "\n",
    "# result = np.zeros((len(output_image), 34))\n",
    "# cCount = None \n",
    "# for i_, img in enumerate(output_image):\n",
    "#     cCount = Counter(img.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Water Way Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799]\n"
     ]
    }
   ],
   "source": [
    "def generateWaterWayMask(waterway, threshold):# between 0 and 4096, need atmost 200 to be water \n",
    "    sizeOfOneMiniBatch = int(len(indices_)/MINIBATCHES_AMT)\n",
    "    waterwayMask = np.zeros((sizeOfOneMiniBatch, 256,256), dtype=np.float32)\n",
    "    for i_ in range(len(waterwayMask)):\n",
    "        waterwayMask[i_] = waterway\n",
    "        \n",
    "    #now that we have the ( 200, 256,256)  (sizeOfOneMiniBatch is 200 for example)\n",
    "    #we can break it up into the 64 by 64 images\n",
    "    waterwayMask64 = split256by256StackOnAxis(waterwayMask)\n",
    "    #from here, you count up each one of the 64 by 64 images and set to the threshold\n",
    "    waterwayMaskIndices = [] # include if they are one \n",
    "    for i_ in range(len(waterwayMask64)):\n",
    "        if(np.sum(waterwayMask64[i_]) <= threshold): #> would mean you have more 1's than allowed -> not tolerable \n",
    "            waterwayMaskIndices.append(i_)\n",
    "    return waterwayMaskIndices\n",
    "\n",
    "ww = np.ones((256,256))\n",
    "ww[:64, (256-64):] = 0\n",
    "\n",
    "abc = generateWaterWayMask(ww, 5)\n",
    "len(abc)\n",
    "print(abc)  # think it works \n",
    "\n",
    "# len(minibatches[10])\n",
    "#stack waterway image by "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for getting the output data (1 hot encoded vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split256by256StackOnAxis(inputImg):\n",
    "    imagesList = np.split(inputImg, 4, axis = 1)\n",
    "    images64by64 = []\n",
    "\n",
    "    for almostImage in imagesList:\n",
    "        imagesList64by64 = np.split(almostImage, 4, axis = 2) # axis is 0, 1, 2\n",
    "        for actual64by64 in imagesList64by64:\n",
    "            images64by64.append(actual64by64)\n",
    "    #     for i,_64 in enumerate(images64by64):\n",
    "    #         print(i, _64.shape)\n",
    "    return np.concatenate(images64by64, axis = 0)\n",
    "\n",
    "def getOutputYVector(y_output_image64, numCats): # y_output_image64 is of shape (3200,64,64)  , 34 categories + -1\n",
    "    result = np.zeros((len(y_output_image64), numCats), dtype=np.float32)\n",
    "    cCount = None \n",
    "    for i_, img in enumerate(y_output_image64):\n",
    "        cCount = Counter(img.flatten())\n",
    "        result[i_][int(cCount.most_common()[0][0])] = 1\n",
    "        #get the argmax for now  -1 goes to 0, 0 goes to 1, etc. until you have 33 going to 34\n",
    "#         result[i_][int(cCount.most_common()[0][0])+1] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1., 2.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[1., 2.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[1., 2.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[1., 2.],\n",
       "        [3., 4.]]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exploring things\n",
    "base_img_mask = np.ones((2, 2), dtype=np.float32)\n",
    "print(base_img_mask.shape)\n",
    "base_img_mask[0,0] = 1\n",
    "base_img_mask[0,1] = 2\n",
    "base_img_mask[1,0] = 3\n",
    "base_img_mask[1,1] = 4\n",
    "\n",
    "base_img_mask\n",
    "\n",
    "np.array([base_img_mask]*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Copy Generation of an image ( numLayers, 256, 256) to  (256, 256, numLayers) and then to  (sampleNum, 256, 256, numLayers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 4)\n",
      "(150, 4)\n",
      "(150, 1, 1, 4)\n",
      "-0.4995\n",
      "{-0.4995}\n"
     ]
    }
   ],
   "source": [
    "###Testing Dates \n",
    "\n",
    "base_img_mask = np.ones((256, 256), dtype=np.float32)\n",
    "xy = np.dstack([base_img_mask]*4)\n",
    "print(xy.shape)\n",
    "\n",
    "dateLayers = datesb[minibatchIndices]\n",
    "print(dateLayers.shape)\n",
    "dateLayersReshaped = dateLayers.reshape((len(dateLayers), 1,1,dateLayers.shape[1]))\n",
    "print(dateLayersReshaped.shape)\n",
    "\n",
    "\n",
    "xyz = xy* dateLayersReshaped \n",
    "xyz.shape\n",
    "\n",
    "#do some checks \n",
    "firstVal = dateLayers[45][1] #last layer, 2nd d value\n",
    "print(firstVal)\n",
    "\n",
    "print(set(xyz[45, :,:, 1].flatten()))\n",
    "#change the 45 and the 1 and see if things match! \n",
    "\n",
    "def generateDatesLayers(minibatchIndices, datesb):\n",
    "    base_img_mask = np.ones((256, 256), dtype=np.float32)\n",
    "    xy = np.dstack([base_img_mask]*4) # shape (256, 256, 4)\n",
    "    dateLayers = datesb[minibatchIndices] # (len(minibatchIndices) , 4)\n",
    "    dateLayersReshaped = dateLayers.reshape((len(dateLayers), 1,1,dateLayers.shape[1])) # (len(minibatchIndices),1,1 , 4)\n",
    "    xyz = xy* dateLayersReshaped \n",
    "    return xyz\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing Null values\n",
    "mask = np.isnan(buildings)\n",
    "indices = np.where(mask ==True)\n",
    "z = indices[0]\n",
    "y = indices[1]\n",
    "x = indices[2]\n",
    "buildings[z,y,x] = -1\n",
    "\n",
    "# mask2 = np.isnan(buildingsTest)\n",
    "# indices2 = np.where(mask2 ==True)\n",
    "# print(indices2)\n",
    "# print(len(indices))\n",
    "# print((indices[0].flatten().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2]\n",
      "  [ 3  4]]\n",
      "\n",
      " [[ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]]]\n",
      "(3, 2, 2)\n",
      "[[5 7]\n",
      " [6 8]]\n",
      "(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "#For transposing images \n",
    "\n",
    "testData = np.array([[[1,2],[3,4]],\n",
    "                    [[5,6],[7,8]],\n",
    "                    [[9,10],[11,12]]])\n",
    "print(testData)\n",
    "print(testData.shape)\n",
    "\n",
    "def transpose3dImage(img):\n",
    "    img_T = img.T #tested this actually does what we wante it to do.  \n",
    "    return img_T\n",
    "\n",
    "testDataT = transpose3dImage(testData) # ( numLayers, 256, 256) to (256, 256, numLayers) \n",
    "\n",
    "print(testDataT[:,:,1])\n",
    "print(testDataT.shape)\n",
    "# dateLayers = generateDatesLayers(minibatchIndices, datesb)\n",
    "# dateLayers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 10)\n",
      "(4, 256, 256, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For  (256, 256, numLayers) and then to (sampleNum, 256, 256, numLayers) \n",
    "\n",
    "def stackManyTimes(_3dimg,times):\n",
    "    _3dimg_shape = _3dimg.shape\n",
    "    result = np.zeros(shape=(times, _3dimg_shape[0], _3dimg_shape[1],_3dimg_shape[2] ), dtype=np.float32)\n",
    "    for x in range(times):\n",
    "        result[x] = _3dimg\n",
    "    return result\n",
    "    \n",
    "buildings2 = np.array(transpose3dImage(buildings))\n",
    "print(buildings2.shape)\n",
    "\n",
    "buildings3_multiplied = stackManyTimes(buildings2, 4)\n",
    "print(buildings3_multiplied.shape)\n",
    "\n",
    "np.where((buildings3_multiplied[3]==buildings2) == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the right output from the list of 52, given that we know that batch size is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "batch min  151200  batch max  69050\n",
      "50   23\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# Getting the right output from the list of 52, we know that batch size is \n",
    "# print(minibatchIndices[])\n",
    "# dateLayers[-1][2]\n",
    "print(len(outputsData))\n",
    "\n",
    "outputsData[51].shape\n",
    "\n",
    "sample = minibatches[0]\n",
    "batchMin = min(sample)#67050\n",
    "batchMax = max(sample)#67199\n",
    "batchMax  = 69050\n",
    "print(\"batch min \" , batchMin,\" batch max \", batchMax )\n",
    "remMin = batchMin % BATCHSIZE_Y\n",
    "multipleMin = int(batchMin / BATCHSIZE_Y)\n",
    "\n",
    "remMax = batchMax % BATCHSIZE_Y\n",
    "multipleMax = int(batchMax / BATCHSIZE_Y)\n",
    "\n",
    "\n",
    "print(multipleMin,\" \",multipleMax)\n",
    "# outputsData[multipleMin-1] # 1 is really 0, 2 is really 1 , and so on. \n",
    "\n",
    "\n",
    "# batchMin\n",
    "#152300 - 152399\n",
    "# 155900 to 155917\n",
    "int(155900/BATCHSIZE_Y)\n",
    "print(remMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "batch = None\n",
    "if(multipleMin != multipleMax):# have to concatenate  batch size can never be more than 3000#\n",
    "    print('here')\n",
    "    batch = np.concatenate((outputsData[multipleMin],outputsData[multipleMax]), axis = 0)\n",
    "else:\n",
    "    print('not here')\n",
    "    batch = outputsData[multipleMin]\n",
    "    \n",
    "offset = multipleMin*BATCHSIZE_Y#+remMin\n",
    "\n",
    "print(offset)\n",
    "batch.shape\n",
    "sample_ = np.array(sample)-offset\n",
    "\n",
    "data_output = batch[sample_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not here\n"
     ]
    }
   ],
   "source": [
    "data_output.shape\n",
    "\n",
    "#very sure that we have to transpose everything -> since we transposed everything in the input layer \n",
    "for i_, img in enumerate(data_output):\n",
    "    data_output[i_] = img.T\n",
    "\n",
    "#now we make the 16, by 16 images \n",
    "\n",
    "sample = minibatches[0]\n",
    "\n",
    "def calculateOutput(sample):\n",
    "    batchMin = min(sample)#67050\n",
    "    batchMax = max(sample)#67199\n",
    "    #     batchMax  = 69050\n",
    "    #print(\"batch min \" , batchMin,\" batch max \", batchMax )\n",
    "    remMin = batchMin % BATCHSIZE_Y\n",
    "    multipleMin = int(batchMin / BATCHSIZE_Y)\n",
    "\n",
    "    remMax = batchMax % BATCHSIZE_Y\n",
    "    multipleMax = int(batchMax / BATCHSIZE_Y)\n",
    "    \n",
    "    batch = None\n",
    "    if(multipleMin != multipleMax):# have to concatenate  batch size can never be more than 3000#\n",
    "        print('here')\n",
    "        batch = np.concatenate((outputsData[multipleMin],outputsData[multipleMax]), axis = 0)\n",
    "    else:\n",
    "        print('not here')\n",
    "        batch = outputsData[multipleMin]\n",
    "\n",
    "    offset = multipleMin*BATCHSIZE_Y\n",
    "    sample_ = np.array(sample)-offset\n",
    "    data_output = batch[sample_]\n",
    "    return data_output\n",
    "\n",
    "\n",
    "output_images = calculateOutput(sample)\n",
    "output_images.shape\n",
    "#( numLayers, 256, 256) to (256, 256, numLayers) \n",
    "#testDataT = transpose3dImage(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-25a97c386e78>:11: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.140359,\n",
       " 3.24087,\n",
       " 15.307369,\n",
       " -15.310234,\n",
       " 6.9300766,\n",
       " 9.067983,\n",
       " -29.766876,\n",
       " 6.4712744,\n",
       " 27.031092,\n",
       " 17.86364]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = .008\n",
    "costs = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    X, Y = create_placeholders(64, 64, 3, 35)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_prop(X, parameters)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#1e-4).minimize(cross_entropy)\n",
    "    #init must be after optimizer\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        _ , temp_cost = sess.run([optimizer,cost], feed_dict={X: np.random.randn(2,64,64,3), Y: np.random.randn(2,35)})\n",
    "        costs.append(temp_cost)\n",
    "        \n",
    "        \n",
    "    #     a = sess.run(cost, {X: np.random.randn(2,64,64,3), Y: np.random.randn(2,35)})\n",
    "    #     print(\"Z3 = \" + str(a))\n",
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zipLoc = cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\New folder\\drive-download-20181203T055115Z-005.zip')\n",
    "# directory = cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\New folder\\\\')+'/'\n",
    "\n",
    "# print(zipLoc)\n",
    "# print(directory)\n",
    "# with zipfile.ZipFile(zipLoc, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(directory)\n",
    "# a = np.load(cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\New folder\\x__buildings_.npy'))\n",
    "# #b = cleanURL(r'C:\\Users\\User\\Documents\\CS230 Project\\new_github\\data_for_cnn_training\\New folder\\y__c16_.npy')\n",
    "# #a = np.load(b)\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]),)\n",
      "(array([0]),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammadayub/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:40: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "/home/muhammadayub/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:41: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "# inputImage, output_image, waterway = generateMinibatch(minibatches[10])\n",
    "#inputImage, output_image = generateMinibatch(minibatches[10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
