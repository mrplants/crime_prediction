{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Anaconda2\\\\envs\\\\py35'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib as pl\n",
    "import numpy as np\n",
    "sys.prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.20.0.\n",
      "The pandas version is 0.23.4.\n"
     ]
    }
   ],
   "source": [
    "#library of functions here\n",
    "#df.dropna()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn \n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "print('The pandas version is {}.'.format(pd.__version__))\n",
    "def normalizeInputs(x, y):\n",
    "    sc = StandardScaler()\n",
    "    x = sc.fit_transform(x)\n",
    "    y = sc.fit_transform(y)\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda2\\envs\\py35\\lib\\site-packages\\pandas\\io\\excel.py:329: FutureWarning: The `sheetname` keyword is deprecated, use `sheet_name` instead\n",
      "  **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr</th>\n",
       "      <th>min</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>categoryCode</th>\n",
       "      <th>Community Area</th>\n",
       "      <th>District</th>\n",
       "      <th>PERCENT AGED UNDER 18 OR OVER 64</th>\n",
       "      <th>PERCENT OF HOUSING CROWDED</th>\n",
       "      <th>PER CAPITA INCOME</th>\n",
       "      <th>PERCENT AGED 16+ UNEMPLOYED</th>\n",
       "      <th>HARDSHIP INDEX</th>\n",
       "      <th>PERCENT HOUSEHOLDS BELOW POVERTY</th>\n",
       "      <th>PERCENT AGED 25+ WITHOUT HIGH SCHOOL DIPLOMA</th>\n",
       "      <th>LiquorStoreCount_District</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>42.005362</td>\n",
       "      <td>-87.671555</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>27.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>23939</td>\n",
       "      <td>8.7</td>\n",
       "      <td>39</td>\n",
       "      <td>23.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>42.004741</td>\n",
       "      <td>-87.665712</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>27.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>23939</td>\n",
       "      <td>8.7</td>\n",
       "      <td>39</td>\n",
       "      <td>23.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>42.014983</td>\n",
       "      <td>-87.666882</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>27.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>23939</td>\n",
       "      <td>8.7</td>\n",
       "      <td>39</td>\n",
       "      <td>23.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>42.008437</td>\n",
       "      <td>-87.673834</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>27.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>23939</td>\n",
       "      <td>8.7</td>\n",
       "      <td>39</td>\n",
       "      <td>23.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>42.021138</td>\n",
       "      <td>-87.668724</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>27.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>23939</td>\n",
       "      <td>8.7</td>\n",
       "      <td>39</td>\n",
       "      <td>23.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hr  min   Latitude  Longitude  categoryCode  Community Area  District  \\\n",
       "0  17    0  42.005362 -87.671555             6               1        24   \n",
       "1  16    0  42.004741 -87.665712            32               1        24   \n",
       "2  10    0  42.014983 -87.666882             8               1        24   \n",
       "3  16    0  42.008437 -87.673834             8               1        24   \n",
       "4  22    0  42.021138 -87.668724            32               1        24   \n",
       "\n",
       "   PERCENT AGED UNDER 18 OR OVER 64  PERCENT OF HOUSING CROWDED  \\\n",
       "0                              27.5                         7.7   \n",
       "1                              27.5                         7.7   \n",
       "2                              27.5                         7.7   \n",
       "3                              27.5                         7.7   \n",
       "4                              27.5                         7.7   \n",
       "\n",
       "   PER CAPITA INCOME   PERCENT AGED 16+ UNEMPLOYED  HARDSHIP INDEX  \\\n",
       "0               23939                          8.7              39   \n",
       "1               23939                          8.7              39   \n",
       "2               23939                          8.7              39   \n",
       "3               23939                          8.7              39   \n",
       "4               23939                          8.7              39   \n",
       "\n",
       "   PERCENT HOUSEHOLDS BELOW POVERTY  \\\n",
       "0                              23.6   \n",
       "1                              23.6   \n",
       "2                              23.6   \n",
       "3                              23.6   \n",
       "4                              23.6   \n",
       "\n",
       "   PERCENT AGED 25+ WITHOUT HIGH SCHOOL DIPLOMA  LiquorStoreCount_District  \n",
       "0                                          18.2                      169.0  \n",
       "1                                          18.2                      169.0  \n",
       "2                                          18.2                      169.0  \n",
       "3                                          18.2                      169.0  \n",
       "4                                          18.2                      169.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in Excel file\n",
    "# path = r'C:/Users/User/Documents/CS230 Project/chicago crime/crime_ocurrences2018-10-24 10-41-33.xlsx'\n",
    "path = r'C:/Users/User/Documents/CS230 Project/chicago crime/crime_socio_lqr_2018-10-25 22-35-49.xlsx'\n",
    "df = pd.read_excel(open(path,'rb'), sheetname='data')\n",
    "\n",
    "print(\"done\")\n",
    "df.head()\n",
    "#https://stackoverflow.com/questions/17063458/reading-an-excel-file-in-python-using-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hr', 'min', 'Latitude', 'Longitude', 'Community Area', 'District', 'PERCENT AGED UNDER 18 OR OVER 64', 'PERCENT OF HOUSING CROWDED', 'PER CAPITA INCOME ', 'PERCENT AGED 16+ UNEMPLOYED', 'HARDSHIP INDEX', 'PERCENT HOUSEHOLDS BELOW POVERTY', 'PERCENT AGED 25+ WITHOUT HIGH SCHOOL DIPLOMA']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "cols = df.columns.tolist()\n",
    "cols.remove('categoryCode')\n",
    "cols.remove('LiquorStoreCount_District')\n",
    "# cols.remove('PER CAPITA INCOME ')\n",
    "\n",
    "# df[cols].head()\n",
    "print(cols)\n",
    "print(len(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# bk = df.copy()\n",
    "\n",
    "#normalize any variables\n",
    "\n",
    "# df['LiquorStoreCount_District'] = df['LiquorStoreCount_District']/df['LiquorStoreCount_District'].max()*100.0\n",
    "df['PER CAPITA INCOME '] = df['PER CAPITA INCOME ']/df['PER CAPITA INCOME '].max()*100.0\n",
    "\n",
    "\n",
    "print(\"done\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(len(df))\n",
    "# len(df.categoryCode.unique().tolist())\n",
    "\n",
    "# abc = df.categoryCode.unique().tolist()\n",
    "# abc.sort()\n",
    "# abc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done randomizing\n",
      "done splitting the data\n"
     ]
    }
   ],
   "source": [
    "classes = 35   # 9 is missing \n",
    "\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"done randomizing\")\n",
    "\n",
    "#just dev and train set\n",
    "test = df[:30000].copy()\n",
    "Y_test = test['categoryCode'].copy().values\n",
    "Y_test = Y_test.reshape(len(Y_test),1)\n",
    "X_test = test[cols].copy().values\n",
    "train = df[30000:].copy()\n",
    "Y_train = train['categoryCode'].copy().values\n",
    "Y_train = Y_train.reshape(len(Y_train),1)\n",
    "\n",
    "X_train = train[cols].copy().values\n",
    "print(\"done splitting the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#normalize the data : https://www.springboard.com/blog/beginners-guide-neural-network-in-python-scikit-learn-0-18/\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "X_train_ = scaler.transform(X_train)\n",
    "X_test_ = scaler.transform(X_test)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1018575, 13)\n",
      "(1018575, 35)\n",
      "(30000, 13)\n",
      "(30000, 35)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pathlib as pl\n",
    "import numpy as np\n",
    "\n",
    "# df =rObj('abc')\n",
    "# a =np.array(df.x.tolist())\n",
    "# b =np.array(df.y.tolist())\n",
    "\n",
    "# x = a\n",
    "# y = b\n",
    "# # x,y = normalizeInputs(a, b)\n",
    "\n",
    "# x_train = x[:9500].reshape(9500, 1)\n",
    "# y_train = y[:9500].reshape(9500, 1)\n",
    "\n",
    "# x_test = x[9500:].reshape(10000-9500, 1)\n",
    "# y_test = y[9500:].reshape(10000-9500, 1)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes=classes)\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=classes)\n",
    "\n",
    "x_train = X_train\n",
    "y_train = Y_train\n",
    "\n",
    "x_test = X_test\n",
    "y_test = Y_test\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "from copy import deepcopy\n",
    "a = deepcopy(Y_test)[:20]\n",
    "a\n",
    "b = keras.utils.to_categorical(a, num_classes=classes)\n",
    "b[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done importing\n",
      "13\n",
      "['hr', 'min', 'Latitude', 'Longitude', 'Community Area', 'District', 'PERCENT AGED UNDER 18 OR OVER 64', 'PERCENT OF HOUSING CROWDED', 'PER CAPITA INCOME ', 'PERCENT AGED 16+ UNEMPLOYED', 'HARDSHIP INDEX', 'PERCENT HOUSEHOLDS BELOW POVERTY', 'PERCENT AGED 25+ WITHOUT HIGH SCHOOL DIPLOMA']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "print('done importing')\n",
    "print(len(cols))\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1018575/1018575 [==============================] - 4s 4us/step - loss: 3.4045 - acc: 0.1705A: 2s - loss: 3\n",
      "Epoch 2/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.5336 - acc: 0.3114\n",
      "Epoch 3/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.3147 - acc: 0.3133\n",
      "Epoch 4/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.2429 - acc: 0.3164A:\n",
      "Epoch 5/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.2247 - acc: 0.3162\n",
      "Epoch 6/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.2141 - acc: 0.3165A: 0s - loss: 2.2143 - acc: 0.316\n",
      "Epoch 7/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.2063 - acc: 0.3173\n",
      "Epoch 8/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1997 - acc: 0.3184\n",
      "Epoch 9/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1940 - acc: 0.3190\n",
      "Epoch 10/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1892 - acc: 0.3196\n",
      "Epoch 11/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1854 - acc: 0.3201\n",
      "Epoch 12/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1819 - acc: 0.3206\n",
      "Epoch 13/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1789 - acc: 0.3214\n",
      "Epoch 14/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1760 - acc: 0.3221A: 0s - loss: 2.1761 - acc: 0.3\n",
      "Epoch 15/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1733 - acc: 0.3225\n",
      "Epoch 16/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1706 - acc: 0.3232\n",
      "Epoch 17/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1683 - acc: 0.3240\n",
      "Epoch 18/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1662 - acc: 0.3246\n",
      "Epoch 19/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1642 - acc: 0.3250\n",
      "Epoch 20/20\n",
      "1018575/1018575 [==============================] - 3s 3us/step - loss: 2.1627 - acc: 0.3254\n",
      "30000/30000 [==============================] - 0s 17us/step\n",
      "Test accuracy: 0.3272333333333333\n",
      "Test Loss  2.1614870995839435\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(28, input_dim=13,  activation='relu'))\n",
    "model.add(Dense(28, activation=tf.nn.relu))\n",
    "model.add(Dense(20, activation=tf.nn.relu))\n",
    "model.add(Dense(20, activation=tf.nn.relu))\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, batch_size = 20000)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test Loss ', test_loss)\n",
    "# Test accuracy: 0.24653333333333333\n",
    "# Test Loss  2.365653770828247\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_3 to have shape (34,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-782bce640bc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1276\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steps_per_epoch'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m         validation_split=validation_split)\n\u001b[0m\u001b[0;32m   1279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[0;32m    915\u001b[0m           \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m           exception_prefix='target')\n\u001b[0m\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[1;34m'Error when checking '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    192\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_3 to have shape (34,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "\n",
    "#plot data\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Dense(units=1,input_shape=(1,))\n",
    "    keras.layers.Dense(5,input_shape=(5,)),\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu),#relu),\n",
    "    keras.layers.Dense(classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), #'sgd',#\n",
    "              loss='categorical_crossentropy',  #mean squared loss, cross entropy \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size = 20000)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "# print('Test accuracy:', test_acc)\n",
    "print('Test Loss', test_loss)\n",
    "\n",
    "# https://stats.stackexchange.com/questions/284189/simple-linear-regression-in-keras\n",
    "# https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "\n",
    "# new_df = pd.DataFrame({'x':x_old.flatten().tolist(), 'y':y_real.flatten().tolist(), 'y_pred':y_new.flatten().tolist()})\n",
    "# pObj(new_df, 'testing1')\n",
    "\n",
    "# y_new2 = model.predict(x_test)\n",
    "# new_d2 = pd.DataFrame({'x':x_test.flatten().tolist(), 'y':y_test.flatten().tolist(), 'y_pred':y_new2.flatten().tolist()})\n",
    "# pObj(new_d2, 'testing2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/4530611/saving-and-loading-objects-and-using-pickle\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "dataPath = r'C:/Users/User/Desktop/newMe/newMe/Training/Stanford/Deep Learning Class/Project/python_code/datafile/'\n",
    "def pObj_old(obj, fileName):\n",
    "    path = dataPath+fileName+\".pickle\"\n",
    "    pickle.dump( obj, open( path, \"wb\" ) )\n",
    "\n",
    "def rObj_old(fileName):\n",
    "    path = dataPath+fileName+\".pickle\"\n",
    "    return pickle.load( open( path, \"rb\" ) )\n",
    "\n",
    "\n",
    "def pObj(df, fileName):\n",
    "    path = dataPath+fileName+\".csv\"\n",
    "    df.to_csv(path, sep=',', index=False)\n",
    "\n",
    "def rObj(fileName):\n",
    "    path = dataPath+fileName+\".csv\"\n",
    "    return pd.read_csv(path, sep=',') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pObj([1,2,[2,\"a\"]], 'abc')\n",
    "# rObj('abc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to test TF neural network with a single variate regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9500, 1)\n",
      "(9500, 1)\n",
      "(500, 1)\n",
      "(500, 1)\n",
      "Epoch 1/15\n",
      "9500/9500 [==============================] - 1s 114us/step - loss: 6013.7831 - acc: 8.4211e-04\n",
      "Epoch 2/15\n",
      "9500/9500 [==============================] - 0s 24us/step - loss: 0.0036 - acc: 0.0011\n",
      "Epoch 3/15\n",
      "9500/9500 [==============================] - 0s 25us/step - loss: 6.4872e-04 - acc: 0.0011\n",
      "Epoch 4/15\n",
      "9500/9500 [==============================] - 0s 24us/step - loss: 6.3381e-04 - acc: 0.0011\n",
      "Epoch 5/15\n",
      "9500/9500 [==============================] - 0s 25us/step - loss: 6.1498e-04 - acc: 0.0011 ETA: 0s - loss: 6.1794e-04 - acc: 0.0012  \n",
      "Epoch 6/15\n",
      "9500/9500 [==============================] - 0s 24us/step - loss: 5.8693e-04 - acc: 0.0011\n",
      "Epoch 7/15\n",
      "9500/9500 [==============================] - 0s 23us/step - loss: 5.6161e-04 - acc: 0.0011\n",
      "Epoch 8/15\n",
      "9500/9500 [==============================] - 0s 25us/step - loss: 5.2795e-04 - acc: 0.0011 ETA: 0s - loss: 5.3899e-04 - acc: 4.9603e-\n",
      "Epoch 9/15\n",
      "9500/9500 [==============================] - 0s 24us/step - loss: 4.8796e-04 - acc: 0.0011\n",
      "Epoch 10/15\n",
      "9500/9500 [==============================] - 0s 23us/step - loss: 4.5389e-04 - acc: 0.0011\n",
      "Epoch 11/15\n",
      "9500/9500 [==============================] - 0s 23us/step - loss: 4.0875e-04 - acc: 0.0011\n",
      "Epoch 12/15\n",
      "9500/9500 [==============================] - 0s 28us/step - loss: 3.6893e-04 - acc: 0.0011\n",
      "Epoch 13/15\n",
      "9500/9500 [==============================] - 0s 25us/step - loss: 3.2768e-04 - acc: 0.0011\n",
      "Epoch 14/15\n",
      "9500/9500 [==============================] - 0s 25us/step - loss: 2.8300e-04 - acc: 0.0011\n",
      "Epoch 15/15\n",
      "9500/9500 [==============================] - 0s 28us/step - loss: 2.3040e-04 - acc: 0.0011\n",
      "500/500 [==============================] - 0s 686us/step\n",
      "Test Loss 0.0001746664772508666\n",
      "Weights= [[1.0169815]] \n",
      "biases= [-0.01623993]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
