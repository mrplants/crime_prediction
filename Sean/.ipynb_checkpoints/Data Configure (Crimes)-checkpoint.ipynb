{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# LOAD CRIME DATA #\n",
    "###################\n",
    "crime_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Crimes (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 6059764\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# CONDITION CRIME DATA #\n",
    "########################\n",
    "# Delete columns that are redundant or unhelpful\n",
    "columns_to_delete = ['Case Number', 'Location Description', 'Block', 'Arrest', 'Domestic', 'FBI Code', 'Primary Type', 'Description','X Coordinate', 'Y Coordinate', 'Year', 'Updated On', 'Location']\n",
    "final_dataframe = crime_dataframe.drop(columns=columns_to_delete).copy().dropna()\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 6059764\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# CONVERT CRIME STATS TO ONE-HOT #\n",
    "##################################\n",
    "# Convert 'Beat', 'District', 'Ward', and 'Community Area' to one-hot vectors\n",
    "beat_one_hot = pd.get_dummies(final_dataframe['Beat'].astype(int))\n",
    "district_one_hot = pd.get_dummies(final_dataframe['District'].astype(int))\n",
    "ward_one_hot = pd.get_dummies(final_dataframe['Ward'].astype(int))\n",
    "community_one_hot = pd.get_dummies(final_dataframe['Community Area'].astype(int))\n",
    "final_dataframe = pd.concat([final_dataframe.drop(columns=['Beat', 'District', 'Ward', 'Community Area']),\n",
    "                            beat_one_hot,\n",
    "                            district_one_hot,\n",
    "                            ward_one_hot,\n",
    "                            community_one_hot], axis=1).dropna()\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 6059764\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# CONDITION DATE #\n",
    "##################\n",
    "# Convert crime dates to YEAR, MONTH, DAY, HOUR, MINUTE, and weekday columns\n",
    "# Convert those to one-hot and concat with final dataframe\n",
    "final_dataframe['Date'] = pd.to_datetime(crime_dataframe['Date'])\n",
    "year_one_hot = pd.get_dummies(final_dataframe['Date'].dt.year.astype(str).apply(lambda x: 'YEAR_'+x))\n",
    "month_one_hot = pd.get_dummies(final_dataframe['Date'].dt.month.apply(lambda x: calendar.month_abbr[x]))\n",
    "day_one_hot = pd.get_dummies(final_dataframe['Date'].dt.day.astype(str).apply(lambda x: 'DAY_'+x))\n",
    "hour_one_hot = pd.get_dummies(final_dataframe['Date'].dt.hour.astype(str).apply(lambda x: 'HOUR_'+x))\n",
    "minute_one_hot = pd.get_dummies(final_dataframe['Date'].dt.minute.astype(str).apply(lambda x: 'MINUTE-'+x))\n",
    "weekday_one_hot = pd.get_dummies(final_dataframe['Date'].dt.weekday.apply(lambda x: calendar.day_name[x]))\n",
    "final_dataframe = pd.concat([final_dataframe,\n",
    "                            year_one_hot,\n",
    "                            month_one_hot,\n",
    "                            day_one_hot,\n",
    "                            hour_one_hot,\n",
    "                            minute_one_hot,\n",
    "                            weekday_one_hot], axis=1).dropna()\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 6018887\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# JOIN TEMPERATURE #\n",
    "####################\n",
    "temperature_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Temperatures (Chicago).csv')\n",
    "# Drop the TAVG column because it has too many NaNs\n",
    "temperature_dataframe = temperature_dataframe.drop(columns=['TAVG'])\n",
    "# Convert the Precipitation, max T, and min T columns to float\n",
    "temperature_dataframe['PRCP'] = pd.to_numeric(temperature_dataframe['PRCP'])\n",
    "temperature_dataframe['TMAX'] = pd.to_numeric(temperature_dataframe['TMAX'])\n",
    "temperature_dataframe['TMIN'] = pd.to_numeric(temperature_dataframe['TMIN'])\n",
    "temperature_dataframe.rename(columns={'PRCP':'PRECIPITATION'})\n",
    "# Join with the final dataframe\n",
    "temperature_dataframe['DATE'] = pd.to_datetime(temperature_dataframe['DATE'])\n",
    "temperature_dataframe['DAY'] = temperature_dataframe['DATE'].dt.day\n",
    "temperature_dataframe['MONTH'] = temperature_dataframe['DATE'].dt.month\n",
    "temperature_dataframe['YEAR'] = temperature_dataframe['DATE'].dt.year\n",
    "final_dataframe['DAY'] = final_dataframe['Date'].dt.day\n",
    "final_dataframe['MONTH'] = final_dataframe['Date'].dt.month\n",
    "final_dataframe['YEAR'] = final_dataframe['Date'].dt.year\n",
    "final_dataframe = final_dataframe.merge(temperature_dataframe, on=['DAY', 'MONTH', 'YEAR'], how='left').drop(columns=['DATE', 'STATION', 'NAME', 'DAY', 'MONTH', 'YEAR']).dropna()\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# JOIN LIFE EXPECTANCY #\n",
    "########################\n",
    "life_expectancy_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Life Expectancy (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# JOIN L ENTRIES #\n",
    "##################\n",
    "L_entry_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/L Station Entries (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# JOIN SBIF GRANTS #\n",
    "####################\n",
    "SBIF_grant_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/SBIF Grants (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# JOIN BUSINESS LICENSES #\n",
    "##########################\n",
    "business_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Business Licenses (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# JOIN SOCIOECONOMIC INDICATORS #\n",
    "#################################\n",
    "socioeconomic_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Socioeconomic Indicators (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the new crime data to a temporary file in my workspace\n",
    "writer = pd.ExcelWriter('/Volumes/GoogleDrive/My Drive/Crime Data/Composite Data/Sean Workspace/23_November.xlsx')\n",
    "final_dataframe.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes not yet joined:\n",
    "#  business licenses\n",
    "#  socioeconomic indicators\n",
    "#  SBIF\n",
    "#  Life Expectancy\n",
    "#  L Entries by Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHS_2001_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2001.csv').dropna()\n",
    "# AHS_2003_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2003.csv').dropna()\n",
    "# AHS_2005_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2005.csv').dropna()\n",
    "# AHS_2007_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2007.csv').dropna()\n",
    "# AHS_2009_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2009.csv').dropna()\n",
    "# AHS_2011_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2011.csv').dropna()\n",
    "# AHS_2013_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2013.csv').dropna()\n",
    "# AHS_2015_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2015.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
