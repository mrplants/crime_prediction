{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import calendar\n",
    "\n",
    "NUM_TIME_BINS_PER_DAY = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# LOAD CRIME DATA #\n",
    "###################\n",
    "crime_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Crimes (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 6059764\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# CONDITION CRIME DATA #\n",
    "########################\n",
    "# Delete columns that are redundant or unhelpful\n",
    "columns_to_delete = ['Case Number', 'Location Description', 'Block', 'Arrest', 'Domestic', 'FBI Code', 'IUCR', 'Description','X Coordinate', 'Y Coordinate', 'Year', 'Updated On', 'Location']\n",
    "final_dataframe = crime_dataframe.drop(columns=columns_to_delete).copy().dropna()\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 6059764\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# CONVERT CRIME STATS TO READABLE #\n",
    "###################################\n",
    "final_dataframe['Beat'] = final_dataframe['Beat'].astype(int).astype(str).apply(lambda x: 'BEAT_'+x)\n",
    "final_dataframe['District'] = final_dataframe['District'].astype(int).astype(str).apply(lambda x: 'DISTRICT_'+x)\n",
    "final_dataframe['Ward'] = final_dataframe['Ward'].astype(int).astype(str).apply(lambda x: 'WARD_'+x)\n",
    "final_dataframe['Community Area'] = final_dataframe['Community Area'].astype(int).astype(str).apply(lambda x: 'COMMUNITY_'+x)\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 6059764\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# CONDITION DATE #\n",
    "##################\n",
    "# Convert crime dates to YEAR, MONTH, DAY, HOUR, MINUTE, and weekday columns\n",
    "# Convert those to one-hot and concat with final dataframe\n",
    "final_dataframe['Date'] = pd.to_datetime(crime_dataframe['Date'])\n",
    "final_dataframe['YEAR'] = final_dataframe['Date'].dt.year.astype(str).apply(lambda x: 'YEAR_'+x)\n",
    "final_dataframe['MONTH'] = final_dataframe['Date'].dt.month.apply(lambda x: calendar.month_abbr[x])\n",
    "final_dataframe['DAY'] = final_dataframe['Date'].dt.day.astype(str).apply(lambda x: 'DAY_'+x)\n",
    "final_dataframe['WEEKDAY'] = final_dataframe['Date'].dt.weekday.apply(lambda x: calendar.day_name[x])\n",
    "hours = final_dataframe['Date'].dt.hour\n",
    "minutes = final_dataframe['Date'].dt.minute\n",
    "final_dataframe['TIME_OF_DAY'] = ((hours + minutes / 60.) / 24. * NUM_TIME_BINS_PER_DAY).astype(int).astype(str).apply(lambda x: 'TIME_SLOT_'+x)\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 6018887\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# JOIN TEMPERATURE #\n",
    "####################\n",
    "temperature_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Temperatures (Chicago).csv')\n",
    "# Drop the TAVG column because it has too many NaNs\n",
    "temperature_dataframe = temperature_dataframe.drop(columns=['TAVG'])\n",
    "# Convert the Precipitation, max T, and min T columns to float\n",
    "temperature_dataframe['PRCP'] = pd.to_numeric(temperature_dataframe['PRCP'])\n",
    "temperature_dataframe['TMAX'] = pd.to_numeric(temperature_dataframe['TMAX'])\n",
    "temperature_dataframe['TMIN'] = pd.to_numeric(temperature_dataframe['TMIN'])\n",
    "temperature_dataframe = temperature_dataframe.rename(columns={'PRCP':'PRECIPITATION', 'TMAX':'MAX TEMP', 'TMIN':'MIN TEMP'})\n",
    "# Join with the final dataframe\n",
    "temperature_dataframe['date_join'] = pd.to_datetime(temperature_dataframe['DATE']).dt.date\n",
    "# Drop unnecessary columns before merge\n",
    "temperature_dataframe = temperature_dataframe.drop(columns=['DATE', 'STATION', 'NAME'])\n",
    "final_dataframe['date_join'] = final_dataframe['Date'].dt.date\n",
    "final_dataframe = final_dataframe.merge(temperature_dataframe, on=['date_join'], how='left').drop(columns=['date_join']).dropna()\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-f89200136dc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msocioeconomic_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocioeconomic_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Community Area Number'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Community Area'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msocioeconomic_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Community Area'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocioeconomic_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Community Area'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'COMMUNITY_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfinal_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocioeconomic_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Community Area'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# JOIN SOCIOECONOMIC INDICATORS #\n",
    "#################################\n",
    "socioeconomic_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Socioeconomic Indicators (Chicago).csv')\n",
    "# Remove unhelpful data\n",
    "socioeconomic_dataframe = socioeconomic_dataframe.drop(columns=['COMMUNITY AREA NAME']).dropna()\n",
    "# This data is only for 2008 - 2012, so filter for that interval\n",
    "final_dataframe = final_dataframe[(final_dataframe['Date'] >= '2008-01-01') & (final_dataframe['Date'] <= '2012-12-31')]['Date']\n",
    "socioeconomic_dataframe = socioeconomic_dataframe.rename(columns={'Community Area Number':'Community Area'})\n",
    "socioeconomic_dataframe['Community Area'] = socioeconomic_dataframe['Community Area'].astype(int).astype(str).apply(lambda x: 'COMMUNITY_'+x)\n",
    "final_dataframe = final_dataframe.merge(socioeconomic_dataframe, on=['Community Area'], how='left').dropna()\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the new crime data to a temporary file in my workspace\n",
    "writer = pd.ExcelWriter('/Volumes/GoogleDrive/My Drive/Crime Data/Composite Data/Sean Workspace/25_November.xlsx')\n",
    "final_dataframe.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# JOIN LIFE EXPECTANCY #\n",
    "########################\n",
    "life_expectancy_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Life Expectancy (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Community Area Number', 'Community Area', '1990 Life Expectancy',\n",
       "       '1990 Lower 95% CI', '1990 Upper 95% CI', '2000 Life Expectancy',\n",
       "       '2000 Lower 95% CI', '2000 Upper 95% CI', '2010 Life Expectancy',\n",
       "       '2010 Lower 95% CI', '2010 Upper 95% CI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "life_expectancy_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# JOIN L ENTRIES #\n",
    "##################\n",
    "L_entry_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/L Station Entries (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station_id', 'stationname', 'date', 'daytype', 'rides'], dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_entry_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# JOIN SBIF GRANTS #\n",
    "####################\n",
    "SBIF_grant_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/SBIF Grants (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company', 'Address', 'TIF District', 'Completion Date', 'Actual Costs',\n",
       "       'Actual Grant', 'Work Items'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBIF_grant_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (9,16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# JOIN BUSINESS LICENSES #\n",
    "##########################\n",
    "business_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Business Licenses (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'LICENSE ID', 'ACCOUNT NUMBER', 'SITE NUMBER', 'LEGAL NAME',\n",
       "       'DOING BUSINESS AS NAME', 'ADDRESS', 'CITY', 'STATE', 'ZIP CODE',\n",
       "       'WARD', 'PRECINCT', 'WARD PRECINCT', 'POLICE DISTRICT', 'LICENSE CODE',\n",
       "       'LICENSE DESCRIPTION', 'BUSINESS ACTIVITY ID', 'BUSINESS ACTIVITY',\n",
       "       'LICENSE NUMBER', 'APPLICATION TYPE', 'APPLICATION CREATED DATE',\n",
       "       'APPLICATION REQUIREMENTS COMPLETE', 'PAYMENT DATE',\n",
       "       'CONDITIONAL APPROVAL', 'LICENSE TERM START DATE',\n",
       "       'LICENSE TERM EXPIRATION DATE', 'LICENSE APPROVED FOR ISSUANCE',\n",
       "       'DATE ISSUED', 'LICENSE STATUS', 'LICENSE STATUS CHANGE DATE', 'SSA',\n",
       "       'LATITUDE', 'LONGITUDE', 'LOCATION'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes not yet joined:\n",
    "#  business licenses\n",
    "#  socioeconomic indicators\n",
    "#  SBIF\n",
    "#  Life Expectancy\n",
    "#  L Entries by Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHS_2001_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2001.csv').dropna()\n",
    "# AHS_2003_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2003.csv').dropna()\n",
    "# AHS_2005_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2005.csv').dropna()\n",
    "# AHS_2007_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2007.csv').dropna()\n",
    "# AHS_2009_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2009.csv').dropna()\n",
    "# AHS_2011_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2011.csv').dropna()\n",
    "# AHS_2013_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2013.csv').dropna()\n",
    "# AHS_2015_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2015.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
