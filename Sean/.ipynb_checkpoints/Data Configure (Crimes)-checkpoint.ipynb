{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import calendar\n",
    "\n",
    "NUM_TIME_BINS_PER_DAY = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# LOAD CRIME DATA #\n",
    "###################\n",
    "crime_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Crimes (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 6059764\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# CONDITION CRIME DATA #\n",
    "########################\n",
    "# Delete columns that are redundant or unhelpful\n",
    "columns_to_delete = ['Case Number', 'Location Description', 'Block', 'Arrest', 'Domestic', 'FBI Code', 'Primary Type', 'Description','X Coordinate', 'Y Coordinate', 'Year', 'Updated On', 'Location']\n",
    "final_dataframe = crime_dataframe.drop(columns=columns_to_delete).copy().dropna()\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 6059764\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# CONVERT CRIME STATS TO READABLE #\n",
    "###################################\n",
    "final_dataframe['Beat'] = final_dataframe['Beat'].astype(str).apply(lambda x: 'BEAT_'+x)\n",
    "final_dataframe['District'] = final_dataframe['District'].astype(str).apply(lambda x: 'DISTRICT_'+x)\n",
    "final_dataframe['Ward'] = final_dataframe['Ward'].astype(str).apply(lambda x: 'WARD_'+x)\n",
    "final_dataframe['Community Area'] = final_dataframe['Community Area'].astype(str).apply(lambda x: 'COMMUNITY_'+x)\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# CONDITION DATE #\n",
    "##################\n",
    "# Convert crime dates to YEAR, MONTH, DAY, HOUR, MINUTE, and weekday columns\n",
    "# Convert those to one-hot and concat with final dataframe\n",
    "final_dataframe['Date'] = pd.to_datetime(crime_dataframe['Date'])\n",
    "final_dataframe['YEAR'] = final_dataframe['Date'].dt.year.astype(str).apply(lambda x: 'YEAR_'+x)\n",
    "final_dataframe['MONTH'] = final_dataframe['Date'].dt.month.apply(lambda x: calendar.month_abbr[x])\n",
    "final_dataframe['DAY'] = final_dataframe['Date'].dt.day.astype(str).apply(lambda x: 'DAY_'+x)\n",
    "final_dataframe['WEEKDAY'] = final_dataframe['Date'].dt.weekday.apply(lambda x: calendar.day_name[x])\n",
    "hours = final_dataframe['Date'].dt.hour\n",
    "minutes = final_dataframe['Date'].dt.minute\n",
    "final_dataframe['TIME_OF_DAY'] = ((hours + minutes / 60.) / 24. * NUM_TIME_BINS_PER_DAY).astype(int).astype(str).apply(lambda x: 'TIME_SLOT_'+x)\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# JOIN TEMPERATURE #\n",
    "####################\n",
    "temperature_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Temperatures (Chicago).csv')\n",
    "# Drop the TAVG column because it has too many NaNs\n",
    "temperature_dataframe = temperature_dataframe.drop(columns=['TAVG'])\n",
    "# Convert the Precipitation, max T, and min T columns to float\n",
    "temperature_dataframe['PRCP'] = pd.to_numeric(temperature_dataframe['PRCP'])\n",
    "temperature_dataframe['TMAX'] = pd.to_numeric(temperature_dataframe['TMAX'])\n",
    "temperature_dataframe['TMIN'] = pd.to_numeric(temperature_dataframe['TMIN'])\n",
    "temperature_dataframe.rename(columns={'PRCP':'PRECIPITATION'})\n",
    "# Join with the final dataframe\n",
    "temperature_dataframe['date_join'] = pd.to_datetime(temperature_dataframe['DATE']).dt.date\n",
    "final_dataframe['date_join'] = final_dataframe['Date'].dt.date\n",
    "final_dataframe = final_dataframe.merge(temperature_dataframe, on=['date_join'], how='left').drop(columns=['DATE', 'STATION', 'NAME', 'date_join']).dropna()\n",
    "print('Length: %d' % len(final_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# JOIN LIFE EXPECTANCY #\n",
    "########################\n",
    "life_expectancy_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Life Expectancy (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# JOIN L ENTRIES #\n",
    "##################\n",
    "L_entry_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/L Station Entries (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# JOIN SBIF GRANTS #\n",
    "####################\n",
    "SBIF_grant_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/SBIF Grants (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# JOIN BUSINESS LICENSES #\n",
    "##########################\n",
    "business_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Business Licenses (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# JOIN SOCIOECONOMIC INDICATORS #\n",
    "#################################\n",
    "socioeconomic_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/Socioeconomic Indicators (Chicago).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# CONVERT TO ONE-HOT #\n",
    "######################\n",
    "# Convert 'Beat', 'District', 'Ward', and 'Community Area' to one-hot vectors\n",
    "one_hot_columns = ['Beat', 'District', 'Ward', 'Community Area', 'YEAR', 'MONTH', 'DAY', 'WEEKDAY', 'TIME_OF_DAY']\n",
    "for column_name in one_hot_columns:\n",
    "    one_hot_expanded_columns = pd.get_dummies(final_dataframe[column_name])\n",
    "    final_dataframe = pd.concat([final_dataframe, one_hot_expanded_columns], axis=1).dropna()\n",
    "final_dataframe.drop(columns=one_hot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the new crime data to a temporary file in my workspace\n",
    "writer = pd.ExcelWriter('/Volumes/GoogleDrive/My Drive/Crime Data/Composite Data/Sean Workspace/25_November.xlsx')\n",
    "final_dataframe.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes not yet joined:\n",
    "#  business licenses\n",
    "#  socioeconomic indicators\n",
    "#  SBIF\n",
    "#  Life Expectancy\n",
    "#  L Entries by Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHS_2001_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2001.csv').dropna()\n",
    "# AHS_2003_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2003.csv').dropna()\n",
    "# AHS_2005_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2005.csv').dropna()\n",
    "# AHS_2007_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2007.csv').dropna()\n",
    "# AHS_2009_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2009.csv').dropna()\n",
    "# AHS_2011_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2011.csv').dropna()\n",
    "# AHS_2013_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2013.csv').dropna()\n",
    "# AHS_2015_dataframe = pd.read_csv('/Volumes/GoogleDrive/My Drive/Crime Data/Raw Data/AHS/2015.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
