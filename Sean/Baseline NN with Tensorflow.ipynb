{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data = pd.read_excel('/Volumes/GoogleDrive/My Drive/Crime Data/Final Folder/25_October.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# HYPERPARAMETERS #\n",
    "###################\n",
    "\n",
    "np.random.seed(0)\n",
    "dev_set_proportion = 0.01\n",
    "test_set_proportion = 0.01\n",
    "train_set_proportion = 1 - (dev_set_proportion + test_set_proportion)\n",
    "learning_rate = 0.001\n",
    "number_epochs = 10000\n",
    "epochs_between_prints = 100\n",
    "epochs_between_saving_cost = 5\n",
    "minibatch_size = np.inf\n",
    "hidden_units_per_layer = 100\n",
    "num_hidden_layers = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# SAVE HYPERPARAMETERS #\n",
    "########################\n",
    "# hyperparameter_data = pd.read.excel('Trials/Hyperparameters.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# CREATE AND CONDITION DATA #\n",
    "#############################\n",
    "\n",
    "# Convert the dataframe to numpy arrays for features and labels\n",
    "features = crime_data.drop(columns=['categoryCode']).values.T\n",
    "labels = crime_data.loc[:,'categoryCode'].values.reshape((-1,1)).T\n",
    "# Drop all NAs that were caught in the transfer\n",
    "feature_cols_with_nans = np.isnan(features).any(axis=0)\n",
    "features = features[:,~feature_cols_with_nans]\n",
    "labels = labels[:,~feature_cols_with_nans]\n",
    "label_cols_with_nans = np.isnan(labels).any(axis=0)\n",
    "features = features[:,~label_cols_with_nans]\n",
    "labels = labels[:,~label_cols_with_nans]\n",
    "\n",
    "n_x, m = features.shape\n",
    "n_y = len(crime_data.loc[:,'categoryCode'].unique())\n",
    "\n",
    "# Shuffle the data\n",
    "order = np.argsort(np.random.random(m))\n",
    "features = features[:,order]\n",
    "labels = labels[:,order]\n",
    "\n",
    "# One Hot Encode the Labels\n",
    "one_hot = np.zeros((n_y,m))\n",
    "one_hot[labels,np.arange(m)] = 1\n",
    "labels = one_hot\n",
    "\n",
    "# Split between train, dev, and test\n",
    "# Data structure: [     TRAIN     ][ DEV ][ TEST ]\n",
    "dev_start_index = int(train_set_proportion*m)\n",
    "test_start_index = dev_start_index + int(dev_set_proportion*m)\n",
    "\n",
    "X_train = features[:, 0:dev_start_index]\n",
    "Y_train = labels[:, 0:dev_start_index]\n",
    "\n",
    "X_dev = features[:, dev_start_index:test_start_index]\n",
    "Y_dev = labels[:, dev_start_index:test_start_index]\n",
    "\n",
    "X_test = features[:, test_start_index:]\n",
    "Y_test = labels[:, test_start_index:]\n",
    "\n",
    "# Normalize the inputs and outputs based on the training set mean and variance\n",
    "x_mean = X_train.mean(axis=1).reshape(n_x,1)\n",
    "x_variance = X_train.var(axis=1).reshape(n_x,1)\n",
    "\n",
    "X_train = (X_train-x_mean)/x_variance\n",
    "X_dev = (X_dev-x_mean)/x_variance\n",
    "X_test = (X_test-x_mean)/x_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    # Creates a list of random minibatches from (X, Y)\n",
    "    m = X.shape[1]\n",
    "    mini_batches = []\n",
    "    \n",
    "    if mini_batch_size > m:\n",
    "        mini_batches.append((X,Y))\n",
    "    else:\n",
    "        # Step 1: Shuffle (X, Y)\n",
    "        permutation = list(np.random.permutation(m))\n",
    "        shuffled_X = X[:, permutation]\n",
    "        shuffled_Y = Y[:, permutation].reshape((1,m))\n",
    "\n",
    "        # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "        num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "        for k in range(0, num_complete_minibatches):\n",
    "            mini_batch_X = shuffled_X[:, k*mini_batch_size: (k+1)*(mini_batch_size)]\n",
    "            mini_batch_Y = shuffled_Y[:, k*mini_batch_size: (k+1)*(mini_batch_size)]\n",
    "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "            mini_batches.append(mini_batch)\n",
    "\n",
    "        # Handling the end case (last mini-batch < mini_batch_size)\n",
    "        if m % mini_batch_size != 0:\n",
    "            mini_batch_X = shuffled_X[:, int(mini_batch_size*np.floor(m/mini_batch_size)): m]\n",
    "            mini_batch_Y = shuffled_Y[:, int(mini_batch_size*np.floor(m/mini_batch_size)): m]\n",
    "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "            mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# CREATE NEURAL NETWORK STRUCTURE #\n",
    "###################################\n",
    "\n",
    "ops.reset_default_graph()\n",
    "\n",
    "# Create placeholders for the featuers and labels\n",
    "X = tf.placeholder(tf.float32, shape=(n_x, None), name='X')\n",
    "Y = tf.placeholder(tf.int32, shape=(n_y, None), name='Y')\n",
    "\n",
    "# Create the network parameters\n",
    "parameters = {}\n",
    "for layer in range(num_hidden_layers+1):\n",
    "    previous_layer_size = (n_x if layer == 0 else hidden_units_per_layer)\n",
    "    this_layer_size = (n_y if layer == num_hidden_layers else hidden_units_per_layer)\n",
    "    W_name = 'W'+str(layer+1)\n",
    "    b_name = 'b'+str(layer+1)\n",
    "    parameters[W_name] = tf.get_variable(W_name,\n",
    "                                         (this_layer_size,previous_layer_size),\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer(seed=1, uniform=False))\n",
    "    parameters[b_name] = tf.get_variable(b_name,\n",
    "                                         (this_layer_size,1),\n",
    "                                         initializer=tf.zeros_initializer())\n",
    "\n",
    "# Hook up the network layers\n",
    "A = X\n",
    "Z = X\n",
    "for layer in range(num_hidden_layers+1):\n",
    "    W = parameters['W'+str(layer+1)]\n",
    "    b = parameters['b'+str(layer+1)]\n",
    "    Z = W@A+b\n",
    "    A = tf.nn.relu(Z)\n",
    "Z_hat = Z\n",
    "Y_hat = tf.argmax(tf.transpose(tf.nn.softmax(tf.transpose(Z_hat))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Epochs\n",
      "\tCost:  3.511786937713623\n",
      "\tTrain Accuracy:  0.124658056\n",
      "\tDev Accuracy:  0.12255603\n",
      "100 Epochs\n",
      "\tCost:  2.2285468578338623\n",
      "\tTrain Accuracy:  0.30704987\n",
      "\tDev Accuracy:  0.30529326\n",
      "200 Epochs\n",
      "\tCost:  2.210200071334839\n",
      "\tTrain Accuracy:  0.30819625\n",
      "\tDev Accuracy:  0.30538866\n",
      "300 Epochs\n",
      "\tCost:  2.1984832286834717\n",
      "\tTrain Accuracy:  0.31637082\n",
      "\tDev Accuracy:  0.31721506\n",
      "400 Epochs\n",
      "\tCost:  2.1832997798919678\n",
      "\tTrain Accuracy:  0.31867525\n",
      "\tDev Accuracy:  0.31807345\n",
      "500 Epochs\n",
      "\tCost:  2.1664490699768066\n",
      "\tTrain Accuracy:  0.32126096\n",
      "\tDev Accuracy:  0.3200763\n",
      "600 Epochs\n",
      "\tCost:  2.1538748741149902\n",
      "\tTrain Accuracy:  0.326842\n",
      "\tDev Accuracy:  0.32789698\n",
      "700 Epochs\n",
      "\tCost:  2.1500208377838135\n",
      "\tTrain Accuracy:  0.32943356\n",
      "\tDev Accuracy:  0.33295184\n",
      "800 Epochs\n",
      "\tCost:  2.1363651752471924\n",
      "\tTrain Accuracy:  0.330686\n",
      "\tDev Accuracy:  0.3315212\n",
      "900 Epochs\n",
      "\tCost:  2.1216254234313965\n",
      "\tTrain Accuracy:  0.3368111\n",
      "\tDev Accuracy:  0.33981878\n",
      "1000 Epochs\n",
      "\tCost:  2.1259398460388184\n",
      "\tTrain Accuracy:  0.33637998\n",
      "\tDev Accuracy:  0.3390558\n",
      "1100 Epochs\n",
      "\tCost:  2.1015801429748535\n",
      "\tTrain Accuracy:  0.3409616\n",
      "\tDev Accuracy:  0.34487364\n",
      "1200 Epochs\n",
      "\tCost:  2.097266912460327\n",
      "\tTrain Accuracy:  0.34200776\n",
      "\tDev Accuracy:  0.34477827\n",
      "1300 Epochs\n",
      "\tCost:  2.1029133796691895\n",
      "\tTrain Accuracy:  0.34102097\n",
      "\tDev Accuracy:  0.3404864\n",
      "1400 Epochs\n",
      "\tCost:  2.076913595199585\n",
      "\tTrain Accuracy:  0.34324172\n",
      "\tDev Accuracy:  0.34620887\n",
      "1500 Epochs\n",
      "\tCost:  2.0663063526153564\n",
      "\tTrain Accuracy:  0.34619042\n",
      "\tDev Accuracy:  0.34773487\n",
      "1600 Epochs\n",
      "\tCost:  2.079493761062622\n",
      "\tTrain Accuracy:  0.3454547\n",
      "\tDev Accuracy:  0.34563664\n",
      "1700 Epochs\n",
      "\tCost:  2.0612924098968506\n",
      "\tTrain Accuracy:  0.3469378\n",
      "\tDev Accuracy:  0.34659037\n",
      "1800 Epochs\n",
      "\tCost:  2.0656981468200684\n",
      "\tTrain Accuracy:  0.34566686\n",
      "\tDev Accuracy:  0.34620887\n",
      "1900 Epochs\n",
      "\tCost:  2.058793783187866\n",
      "\tTrain Accuracy:  0.3443959\n",
      "\tDev Accuracy:  0.34487364\n",
      "2000 Epochs\n",
      "\tCost:  2.085218906402588\n",
      "\tTrain Accuracy:  0.34055096\n",
      "\tDev Accuracy:  0.3416309\n",
      "2100 Epochs\n",
      "\tCost:  2.0551724433898926\n",
      "\tTrain Accuracy:  0.34981057\n",
      "\tDev Accuracy:  0.3505961\n",
      "2200 Epochs\n",
      "\tCost:  2.0474166870117188\n",
      "\tTrain Accuracy:  0.3518591\n",
      "\tDev Accuracy:  0.35231283\n",
      "2300 Epochs\n",
      "\tCost:  2.0514705181121826\n",
      "\tTrain Accuracy:  0.34757328\n",
      "\tDev Accuracy:  0.3490701\n",
      "2400 Epochs\n",
      "\tCost:  2.0488250255584717\n",
      "\tTrain Accuracy:  0.35067084\n",
      "\tDev Accuracy:  0.35069147\n",
      "2500 Epochs\n",
      "\tCost:  2.0447638034820557\n",
      "\tTrain Accuracy:  0.35301226\n",
      "\tDev Accuracy:  0.35488793\n",
      "2600 Epochs\n",
      "\tCost:  2.039072036743164\n",
      "\tTrain Accuracy:  0.35417032\n",
      "\tDev Accuracy:  0.35603243\n",
      "2700 Epochs\n",
      "\tCost:  2.0435872077941895\n",
      "\tTrain Accuracy:  0.35295972\n",
      "\tDev Accuracy:  0.35441107\n",
      "2800 Epochs\n",
      "\tCost:  2.036444902420044\n",
      "\tTrain Accuracy:  0.3540049\n",
      "\tDev Accuracy:  0.35822603\n",
      "2900 Epochs\n",
      "\tCost:  2.0490150451660156\n",
      "\tTrain Accuracy:  0.3489902\n",
      "\tDev Accuracy:  0.3501192\n",
      "3000 Epochs\n",
      "\tCost:  2.046157121658325\n",
      "\tTrain Accuracy:  0.35177442\n",
      "\tDev Accuracy:  0.35288507\n",
      "3100 Epochs\n",
      "\tCost:  2.0318446159362793\n",
      "\tTrain Accuracy:  0.35574004\n",
      "\tDev Accuracy:  0.35546017\n",
      "3200 Epochs\n",
      "\tCost:  2.0281074047088623\n",
      "\tTrain Accuracy:  0.35709858\n",
      "\tDev Accuracy:  0.35755843\n",
      "3300 Epochs\n",
      "\tCost:  2.045578718185425\n",
      "\tTrain Accuracy:  0.3536059\n",
      "\tDev Accuracy:  0.3568908\n",
      "3400 Epochs\n",
      "\tCost:  2.03141450881958\n",
      "\tTrain Accuracy:  0.3573302\n",
      "\tDev Accuracy:  0.35784453\n",
      "3500 Epochs\n",
      "\tCost:  2.035578966140747\n",
      "\tTrain Accuracy:  0.35551816\n",
      "\tDev Accuracy:  0.35784453\n",
      "3600 Epochs\n",
      "\tCost:  2.0322439670562744\n",
      "\tTrain Accuracy:  0.3540594\n",
      "\tDev Accuracy:  0.35784453\n",
      "3700 Epochs\n",
      "\tCost:  2.0456724166870117\n",
      "\tTrain Accuracy:  0.3534249\n",
      "\tDev Accuracy:  0.3542203\n",
      "3800 Epochs\n",
      "\tCost:  2.0271482467651367\n",
      "\tTrain Accuracy:  0.35729125\n",
      "\tDev Accuracy:  0.3587029\n",
      "3900 Epochs\n",
      "\tCost:  2.030363082885742\n",
      "\tTrain Accuracy:  0.35666066\n",
      "\tDev Accuracy:  0.3583214\n",
      "4000 Epochs\n",
      "\tCost:  2.0217082500457764\n",
      "\tTrain Accuracy:  0.35882887\n",
      "\tDev Accuracy:  0.36118263\n",
      "4100 Epochs\n",
      "\tCost:  2.0365383625030518\n",
      "\tTrain Accuracy:  0.35086355\n",
      "\tDev Accuracy:  0.35116833\n",
      "4200 Epochs\n",
      "\tCost:  2.0438344478607178\n",
      "\tTrain Accuracy:  0.35379568\n",
      "\tDev Accuracy:  0.35622317\n",
      "4300 Epochs\n",
      "\tCost:  2.031363010406494\n",
      "\tTrain Accuracy:  0.35672876\n",
      "\tDev Accuracy:  0.35517406\n",
      "4400 Epochs\n",
      "\tCost:  2.033175230026245\n",
      "\tTrain Accuracy:  0.35786834\n",
      "\tDev Accuracy:  0.35708153\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# EXECUTE MODEL #\n",
    "#################\n",
    "\n",
    "# Calculate the cost from the network prediction\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=tf.transpose(Z_hat),\n",
    "                                                                 labels=tf.transpose(Y)))\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "# Formula for calculating set accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Z_hat), tf.argmax(Y)), \"float\"))\n",
    "\n",
    "costs = []\n",
    "train_accuracies = []\n",
    "dev_accuracies = []\n",
    "\n",
    "# Run the tf session to train and test\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    for epoch in range(number_epochs):\n",
    "        epoch_cost = 0.\n",
    "        num_minibatches = int(m / minibatch_size)\n",
    "        if num_minibatches < 1: num_minibatches=1\n",
    "        minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "        for minibatch in minibatches:\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "            _ , minibatch_cost = session.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "            epoch_cost += minibatch_cost / num_minibatches\n",
    "        \n",
    "        # Data Analysis\n",
    "        if epoch % epochs_between_prints == 0:\n",
    "            print('%i Epochs' % epoch)\n",
    "            print('\\tCost: ', epoch_cost)\n",
    "            print('\\tTrain Accuracy: ', accuracy.eval({X: X_train, Y: Y_train}))\n",
    "            print('\\tDev Accuracy: ', accuracy.eval({X: X_dev, Y: Y_dev}))\n",
    "\n",
    "        if epoch % epochs_between_saving_cost == 0:\n",
    "            costs.append(epoch_cost)\n",
    "            train_accuracies.append(accuracy.eval({X: X_train, Y: Y_train}))\n",
    "            dev_accuracies.append(accuracy.eval({X: X_dev, Y: Y_dev}))\n",
    "\n",
    "    # Calculate the accuracy on the train and dev sets\n",
    "\n",
    "    print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "    print (\"Dev Accuracy:\", accuracy.eval({X: X_dev, Y: Y_dev}))\n",
    "\n",
    "# Plot cost\n",
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Iterations (by 5)')\n",
    "plt.title('Learning rate = ' + str(learning_rate))\n",
    "plt.show()\n",
    "\n",
    "# Plot train and dev accuracy\n",
    "plt.plot(np.squeeze(train_accuracies))\n",
    "plt.plot(np.squeeze(dev_accuracies))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Iterations (by 5)')\n",
    "plt.title('Learning rate = ' + str(learning_rate))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
